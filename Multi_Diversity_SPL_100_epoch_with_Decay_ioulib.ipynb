{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a55b1f0-82ab-4922-b781-625766c4e7b9",
      "metadata": {
        "id": "7a55b1f0-82ab-4922-b781-625766c4e7b9",
        "outputId": "a04c6db6-2a52-4889-9d7a-fc7265cbf30e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydicom in ./lib/python3.10/site-packages (2.4.4)\n",
            "Requirement already satisfied: nibabel in ./lib/python3.10/site-packages (5.2.0)\n",
            "Requirement already satisfied: numpy in ./lib/python3.10/site-packages (1.26.4)\n",
            "Requirement already satisfied: torch in ./lib/python3.10/site-packages (2.2.0)\n",
            "Requirement already satisfied: torchvision in ./lib/python3.10/site-packages (0.17.0)\n",
            "Requirement already satisfied: segmentation-models-pytorch in ./lib/python3.10/site-packages (0.3.3)\n",
            "Requirement already satisfied: scikit-learn in ./lib/python3.10/site-packages (1.4.0)\n",
            "Requirement already satisfied: packaging>=17 in ./lib/python3.10/site-packages (from nibabel) (23.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in ./lib/python3.10/site-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in ./lib/python3.10/site-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: jinja2 in ./lib/python3.10/site-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: networkx in ./lib/python3.10/site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: filelock in ./lib/python3.10/site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: sympy in ./lib/python3.10/site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in ./lib/python3.10/site-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: fsspec in ./lib/python3.10/site-packages (from torch) (2024.2.0)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./lib/python3.10/site-packages (from torchvision) (10.2.0)\n",
            "Requirement already satisfied: requests in ./lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: timm==0.9.2 in ./lib/python3.10/site-packages (from segmentation-models-pytorch) (0.9.2)\n",
            "Requirement already satisfied: pretrainedmodels==0.7.4 in ./lib/python3.10/site-packages (from segmentation-models-pytorch) (0.7.4)\n",
            "Requirement already satisfied: tqdm in ./lib/python3.10/site-packages (from segmentation-models-pytorch) (4.66.2)\n",
            "Requirement already satisfied: efficientnet-pytorch==0.7.1 in ./lib/python3.10/site-packages (from segmentation-models-pytorch) (0.7.1)\n",
            "Requirement already satisfied: munch in ./lib/python3.10/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.0.0)\n",
            "Requirement already satisfied: safetensors in ./lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.2)\n",
            "Requirement already satisfied: pyyaml in ./lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in ./lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.20.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in ./lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in ./lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./lib/python3.10/site-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./lib/python3.10/site-packages (from requests->torchvision) (2024.2.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./lib/python3.10/site-packages (from requests->torchvision) (2.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in ./lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pydicom nibabel numpy torch torchvision segmentation-models-pytorch scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c72e24cf-4548-4014-b732-434bb08f3b99",
      "metadata": {
        "id": "c72e24cf-4548-4014-b732-434bb08f3b99",
        "outputId": "73930a53-7e5f-472b-d79c-81848f824f96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: albumentations in ./lib/python3.10/site-packages (1.3.1)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in ./lib/python3.10/site-packages (from albumentations) (0.22.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in ./lib/python3.10/site-packages (from albumentations) (4.9.0.80)\n",
            "Requirement already satisfied: qudida>=0.0.4 in ./lib/python3.10/site-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: numpy>=1.11.1 in ./lib/python3.10/site-packages (from albumentations) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in ./lib/python3.10/site-packages (from albumentations) (1.12.0)\n",
            "Requirement already satisfied: PyYAML in ./lib/python3.10/site-packages (from albumentations) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions in ./lib/python3.10/site-packages (from qudida>=0.0.4->albumentations) (4.9.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in ./lib/python3.10/site-packages (from qudida>=0.0.4->albumentations) (1.4.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in ./lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (2024.2.12)\n",
            "Requirement already satisfied: pillow>=9.0.1 in ./lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (10.2.0)\n",
            "Requirement already satisfied: networkx>=2.8 in ./lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (3.2.1)\n",
            "Requirement already satisfied: packaging>=21 in ./lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (23.2)\n",
            "Requirement already satisfied: lazy_loader>=0.3 in ./lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (0.3)\n",
            "Requirement already satisfied: imageio>=2.27 in ./lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (2.34.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./lib/python3.10/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in ./lib/python3.10/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.2.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "259e95b5-55e5-49b0-846d-4520caffa2e1",
      "metadata": {
        "id": "259e95b5-55e5-49b0-846d-4520caffa2e1",
        "outputId": "2573e8f0-67fc-4950-fb0c-86ba87c2247d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in ./lib/python3.10/site-packages (2.2.0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./lib/python3.10/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./lib/python3.10/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./lib/python3.10/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in ./lib/python3.10/site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: six>=1.5 in ./lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0004d78c-3260-4376-9f89-6601f0f197a9",
      "metadata": {
        "id": "0004d78c-3260-4376-9f89-6601f0f197a9",
        "outputId": "b2c5e6b1-3172-40b5-e71b-826de9c0cc6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/100] - Train IoU: 0.0799 - Validation IoU: 0.0508\n",
            "Epoch [2/100] - Train IoU: 0.1111 - Validation IoU: 0.0698\n",
            "Epoch [3/100] - Train IoU: 0.1188 - Validation IoU: 0.1131\n",
            "Epoch [4/100] - Train IoU: 0.1606 - Validation IoU: 0.1282\n",
            "Epoch [5/100] - Train IoU: 0.1750 - Validation IoU: 0.1425\n",
            "Epoch [6/100] - Train IoU: 0.1561 - Validation IoU: 0.1419\n",
            "Epoch [7/100] - Train IoU: 0.2040 - Validation IoU: 0.1608\n",
            "Epoch [8/100] - Train IoU: 0.2658 - Validation IoU: 0.1840\n",
            "Epoch [9/100] - Train IoU: 0.2976 - Validation IoU: 0.2074\n",
            "Epoch [10/100] - Train IoU: 0.3385 - Validation IoU: 0.2356\n",
            "Epoch [11/100] - Train IoU: 0.4051 - Validation IoU: 0.2635\n",
            "Epoch [12/100] - Train IoU: 0.2931 - Validation IoU: 0.2933\n",
            "Epoch [13/100] - Train IoU: 0.5083 - Validation IoU: 0.3349\n",
            "Epoch [14/100] - Train IoU: 0.5382 - Validation IoU: 0.3742\n",
            "Epoch [15/100] - Train IoU: 0.4288 - Validation IoU: 0.3943\n",
            "Epoch [16/100] - Train IoU: 0.4828 - Validation IoU: 0.4216\n",
            "Epoch [17/100] - Train IoU: 0.6516 - Validation IoU: 0.4455\n",
            "Epoch [18/100] - Train IoU: 0.6558 - Validation IoU: 0.4942\n",
            "Epoch [19/100] - Train IoU: 0.5770 - Validation IoU: 0.5251\n",
            "Epoch [20/100] - Train IoU: 0.6318 - Validation IoU: 0.5481\n",
            "Epoch [21/100] - Train IoU: 0.6718 - Validation IoU: 0.5744\n",
            "Epoch [22/100] - Train IoU: 0.5953 - Validation IoU: 0.5901\n",
            "Epoch [23/100] - Train IoU: 0.6683 - Validation IoU: 0.6213\n",
            "Epoch [24/100] - Train IoU: 0.7400 - Validation IoU: 0.6406\n",
            "Epoch [25/100] - Train IoU: 0.6672 - Validation IoU: 0.6655\n",
            "Epoch [26/100] - Train IoU: 0.7116 - Validation IoU: 0.6811\n",
            "Epoch [27/100] - Train IoU: 0.7557 - Validation IoU: 0.6901\n",
            "Epoch [28/100] - Train IoU: 0.7881 - Validation IoU: 0.6874\n",
            "Epoch [29/100] - Train IoU: 0.7722 - Validation IoU: 0.7018\n",
            "Epoch [30/100] - Train IoU: 0.7770 - Validation IoU: 0.7101\n",
            "Epoch [31/100] - Train IoU: 0.7923 - Validation IoU: 0.7244\n",
            "Epoch [32/100] - Train IoU: 0.8057 - Validation IoU: 0.7391\n",
            "Epoch [33/100] - Train IoU: 0.7962 - Validation IoU: 0.7542\n",
            "Epoch [34/100] - Train IoU: 0.6805 - Validation IoU: 0.7438\n",
            "Epoch [35/100] - Train IoU: 0.7771 - Validation IoU: 0.7447\n",
            "Epoch [36/100] - Train IoU: 0.7646 - Validation IoU: 0.7646\n",
            "Epoch [37/100] - Train IoU: 0.7541 - Validation IoU: 0.7715\n",
            "Epoch [38/100] - Train IoU: 0.8349 - Validation IoU: 0.7806\n",
            "Epoch [39/100] - Train IoU: 0.8212 - Validation IoU: 0.7903\n",
            "Epoch [40/100] - Train IoU: 0.7747 - Validation IoU: 0.8014\n",
            "Epoch [41/100] - Train IoU: 0.8206 - Validation IoU: 0.8135\n",
            "Epoch [42/100] - Train IoU: 0.8506 - Validation IoU: 0.8277\n",
            "Epoch [43/100] - Train IoU: 0.8259 - Validation IoU: 0.8275\n",
            "Epoch [44/100] - Train IoU: 0.7822 - Validation IoU: 0.8254\n",
            "Epoch [45/100] - Train IoU: 0.8571 - Validation IoU: 0.8239\n",
            "Epoch [46/100] - Train IoU: 0.8427 - Validation IoU: 0.8181\n",
            "Epoch [47/100] - Train IoU: 0.8394 - Validation IoU: 0.8264\n",
            "Epoch [48/100] - Train IoU: 0.8348 - Validation IoU: 0.8346\n",
            "Epoch [49/100] - Train IoU: 0.8763 - Validation IoU: 0.8391\n",
            "Epoch [50/100] - Train IoU: 0.8845 - Validation IoU: 0.8433\n",
            "Epoch [51/100] - Train IoU: 0.8842 - Validation IoU: 0.8455\n",
            "Epoch [52/100] - Train IoU: 0.8666 - Validation IoU: 0.8429\n",
            "Epoch [53/100] - Train IoU: 0.8956 - Validation IoU: 0.8405\n",
            "Epoch [54/100] - Train IoU: 0.8510 - Validation IoU: 0.8444\n",
            "Epoch [55/100] - Train IoU: 0.8592 - Validation IoU: 0.8524\n",
            "Epoch [56/100] - Train IoU: 0.9032 - Validation IoU: 0.8569\n",
            "Epoch [57/100] - Train IoU: 0.8673 - Validation IoU: 0.8597\n",
            "Epoch [58/100] - Train IoU: 0.8848 - Validation IoU: 0.8602\n",
            "Epoch [59/100] - Train IoU: 0.8951 - Validation IoU: 0.8573\n",
            "Epoch [60/100] - Train IoU: 0.7973 - Validation IoU: 0.8497\n",
            "Epoch [61/100] - Train IoU: 0.8869 - Validation IoU: 0.8538\n",
            "Epoch [62/100] - Train IoU: 0.8626 - Validation IoU: 0.8437\n",
            "Epoch [63/100] - Train IoU: 0.9202 - Validation IoU: 0.8539\n",
            "Epoch [64/100] - Train IoU: 0.8912 - Validation IoU: 0.8553\n",
            "Epoch [65/100] - Train IoU: 0.8647 - Validation IoU: 0.8583\n",
            "Epoch [66/100] - Train IoU: 0.9027 - Validation IoU: 0.8603\n",
            "Epoch [67/100] - Train IoU: 0.8955 - Validation IoU: 0.8615\n",
            "Epoch [68/100] - Train IoU: 0.9288 - Validation IoU: 0.8643\n",
            "Epoch [69/100] - Train IoU: 0.8901 - Validation IoU: 0.8681\n",
            "Epoch [70/100] - Train IoU: 0.9084 - Validation IoU: 0.8666\n",
            "Epoch [71/100] - Train IoU: 0.9134 - Validation IoU: 0.8699\n",
            "Epoch [72/100] - Train IoU: 0.9249 - Validation IoU: 0.8749\n",
            "Epoch [73/100] - Train IoU: 0.9206 - Validation IoU: 0.8790\n",
            "Epoch [74/100] - Train IoU: 0.9224 - Validation IoU: 0.8788\n",
            "Epoch [75/100] - Train IoU: 0.8870 - Validation IoU: 0.8795\n",
            "Epoch [76/100] - Train IoU: 0.9318 - Validation IoU: 0.8823\n",
            "Epoch [77/100] - Train IoU: 0.9139 - Validation IoU: 0.8785\n",
            "Epoch [78/100] - Train IoU: 0.9044 - Validation IoU: 0.8732\n",
            "Epoch [79/100] - Train IoU: 0.9035 - Validation IoU: 0.8751\n",
            "Epoch [80/100] - Train IoU: 0.9283 - Validation IoU: 0.8798\n",
            "Epoch [81/100] - Train IoU: 0.8708 - Validation IoU: 0.8828\n",
            "Epoch [82/100] - Train IoU: 0.9233 - Validation IoU: 0.8855\n",
            "Epoch [83/100] - Train IoU: 0.9093 - Validation IoU: 0.8820\n",
            "Epoch [84/100] - Train IoU: 0.9161 - Validation IoU: 0.8836\n",
            "Epoch [85/100] - Train IoU: 0.9291 - Validation IoU: 0.8844\n",
            "Epoch [86/100] - Train IoU: 0.9428 - Validation IoU: 0.8848\n",
            "Epoch [87/100] - Train IoU: 0.9265 - Validation IoU: 0.8850\n",
            "Epoch [88/100] - Train IoU: 0.9368 - Validation IoU: 0.8894\n",
            "Epoch [89/100] - Train IoU: 0.9159 - Validation IoU: 0.8898\n",
            "Epoch [90/100] - Train IoU: 0.9319 - Validation IoU: 0.8896\n",
            "Epoch [91/100] - Train IoU: 0.9373 - Validation IoU: 0.8867\n",
            "Epoch [92/100] - Train IoU: 0.9161 - Validation IoU: 0.8870\n",
            "Epoch [93/100] - Train IoU: 0.9318 - Validation IoU: 0.8853\n",
            "Epoch [94/100] - Train IoU: 0.9140 - Validation IoU: 0.8861\n",
            "Epoch [95/100] - Train IoU: 0.8661 - Validation IoU: 0.8800\n",
            "Epoch [96/100] - Train IoU: 0.9350 - Validation IoU: 0.8824\n",
            "Epoch [97/100] - Train IoU: 0.9325 - Validation IoU: 0.8851\n",
            "Epoch [98/100] - Train IoU: 0.9384 - Validation IoU: 0.8882\n",
            "Epoch [99/100] - Train IoU: 0.9403 - Validation IoU: 0.8930\n",
            "Epoch [100/100] - Train IoU: 0.9345 - Validation IoU: 0.8935\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import nibabel as nib\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import random\n",
        "import segmentation_models_pytorch as smp\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from scipy.ndimage import zoom\n",
        "from operator import itemgetter\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "num_classes = 7\n",
        "batch_size = 8\n",
        "img_root = \"/home/ealam/JHIR_Hip_Knee_Datasets/Hip/Images\"\n",
        "mask_root = \"/home/ealam/JHIR_Hip_Knee_Datasets/Hip/Annotations\"\n",
        "metadata_path = \"/home/ealam/JHIR_Hip_Knee_Datasets/Hip/segmentation_with_racegender.csv\"\n",
        "test_augmentations = A.Compose([\n",
        "    A.Resize(height=256, width=256),\n",
        "    A.Normalize(mean=(0.485,), std=(0.229,)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "class MulticlassHipSegmentationDataset(Dataset):\n",
        "    def __init__(self, img_root, mask_root, metadata_df, paired_files, num_classes, transforms=None, preprocessing=None):\n",
        "        self.img_root = img_root\n",
        "        self.mask_root = mask_root\n",
        "        self.metadata_df = metadata_df\n",
        "        self.paired_files = paired_files\n",
        "        self.num_classes = num_classes\n",
        "        self.transforms = transforms\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paired_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_file, mask_file = self.paired_files[idx]\n",
        "        if not os.path.exists(os.path.join(self.mask_root, mask_file)):\n",
        "            return None\n",
        "\n",
        "        dicom_image = pydicom.dcmread(os.path.join(self.img_root, image_file))\n",
        "        image = dicom_image.pixel_array.astype(np.float32)\n",
        "        annotation = nib.load(os.path.join(self.mask_root, mask_file))\n",
        "        annotation_data = annotation.get_fdata()\n",
        "        if len(annotation_data.shape) == 3:\n",
        "            annotation_data = annotation_data[:, :, 0]\n",
        "\n",
        "        annotation_data = self.calculate_flipped_rotated_mask(annotation_data)\n",
        "\n",
        "        if annotation_data.ndim > 2 and annotation_data.shape[-1] != 1:\n",
        "            raise ValueError('Mask has multiple channels')\n",
        "\n",
        "        if image.shape != annotation_data.shape:\n",
        "            zoom_factors = np.array(image.shape) / np.array(annotation_data.shape)\n",
        "            annotation_data = zoom(annotation_data, zoom_factors, order=0)\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            transformed = self.transforms(image=image, mask=annotation_data)\n",
        "            image = transformed[\"image\"]\n",
        "            annotation_data = transformed[\"mask\"]\n",
        "\n",
        "        annotation_data_onehot = self.one_hot_encode(annotation_data)\n",
        "\n",
        "        if self.preprocessing is not None:\n",
        "            transformed = self.preprocessing(image=image, mask=annotation_data_onehot)\n",
        "            image = transformed[\"image\"]\n",
        "            annotation_data_onehot = transformed[\"mask\"]\n",
        "\n",
        "        patient_id = int(float(image_file.split(\".\")[0]))\n",
        "        racegender_info = self.metadata_df.loc[self.metadata_df['id'] == patient_id]['racegender'].values\n",
        "        racegender = racegender_info[0] if racegender_info else 'Unknown'\n",
        "\n",
        "        return image, annotation_data_onehot, racegender\n",
        "\n",
        "    def one_hot_encode(self, mask):\n",
        "        one_hot_mask = np.zeros((self.num_classes, *mask.shape), dtype=np.float32)\n",
        "        for class_idx in range(self.num_classes):\n",
        "            one_hot_mask[class_idx][mask == class_idx] = 1.0\n",
        "        return one_hot_mask\n",
        "\n",
        "    def calculate_flipped_rotated_mask(self, mask):\n",
        "        rotated_mask = cv2.rotate(mask, cv2.ROTATE_90_CLOCKWISE)\n",
        "        flipped_rotated_mask = cv2.flip(rotated_mask, 1)\n",
        "        return flipped_rotated_mask\n",
        "\n",
        "metadata_df = pd.read_csv(metadata_path)\n",
        "\n",
        "image_files = sorted(os.listdir(img_root))\n",
        "mask_files = sorted(os.listdir(mask_root))\n",
        "\n",
        "paired_files = []\n",
        "\n",
        "for image_file in image_files:\n",
        "    image_id = os.path.splitext(image_file)[0]\n",
        "    mask_file = f\"{image_id}.nii.gz\"\n",
        "    if mask_file in mask_files:\n",
        "        paired_files.append((image_file, mask_file))\n",
        "\n",
        "random.shuffle(paired_files)\n",
        "\n",
        "train_size = int(0.7 * len(paired_files))\n",
        "valid_size = int(0.1 * len(paired_files))\n",
        "test_size = len(paired_files) - train_size - valid_size\n",
        "\n",
        "train_pairs = paired_files[:train_size]\n",
        "valid_pairs = paired_files[train_size:train_size + valid_size]\n",
        "test_pairs = paired_files[train_size + valid_size:]\n",
        "\n",
        "train_set = MulticlassHipSegmentationDataset(\n",
        "    img_root, mask_root, metadata_df, train_pairs, num_classes,\n",
        "    transforms=test_augmentations\n",
        ")\n",
        "\n",
        "model = smp.Unet(\n",
        "    encoder_name=\"resnet18\",\n",
        "    encoder_weights=\"imagenet\",\n",
        "    in_channels=1,\n",
        "    classes=num_classes,\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "valid_set = MulticlassHipSegmentationDataset(\n",
        "    img_root, mask_root, metadata_df, valid_pairs, num_classes,\n",
        "    transforms=test_augmentations\n",
        ")\n",
        "\n",
        "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "num_epochs = 100\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    iou_racegender_list = []\n",
        "\n",
        "    for batch_idx, (images, masks, racegender) in enumerate(train_loader):\n",
        "        if images is None:\n",
        "            continue\n",
        "\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        predicted_masks = torch.argmax(outputs, dim=1)\n",
        "        loss = criterion(outputs, masks.argmax(dim=1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_iou = jaccard_score(\n",
        "            masks.argmax(dim=1).cpu().numpy().flatten(),\n",
        "            predicted_masks.cpu().numpy().flatten(),\n",
        "            average='micro'\n",
        "        )\n",
        "        iou_racegender_list.append((train_iou, batch_idx, racegender))\n",
        "\n",
        "    if epoch > 2:\n",
        "        # Sort the list of IoU values, indices, and racegender in descending order based on IoU values\n",
        "        iou_racegender_list.sort(reverse=True, key=itemgetter(0))\n",
        "\n",
        "        # Extract unique racegenders\n",
        "        racegenders = set(racegender for _, _, racegender in iou_racegender_list)\n",
        "\n",
        "        # Create dictionaries to store sorted lists of IoU values and indices for each racegender\n",
        "        racegender_lists = {racegender: [] for racegender in racegenders}\n",
        "        for iou, idx, racegender in iou_racegender_list:\n",
        "            racegender_lists[racegender].append((iou, idx))\n",
        "\n",
        "        # Reconstruct DataLoader based on sorted indices and alternating racegenders\n",
        "        sorted_indices = []\n",
        "        for racegender in racegenders:\n",
        "            sorted_indices.extend([idx for _, idx in racegender_lists[racegender]])\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            train_set,\n",
        "            batch_size=batch_size,\n",
        "            sampler=torch.utils.data.sampler.SubsetRandomSampler(sorted_indices),\n",
        "            num_workers=2\n",
        "        )\n",
        "\n",
        "    model.eval()\n",
        "    valid_iou_list = []\n",
        "\n",
        "    for batch_idx, (images, masks, racegender) in enumerate(valid_loader):\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(images)\n",
        "        predicted_masks = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        valid_iou = jaccard_score(\n",
        "            masks.argmax(dim=1).cpu().numpy().flatten(),\n",
        "            predicted_masks.cpu().numpy().flatten(),\n",
        "            average='micro'\n",
        "        )\n",
        "\n",
        "        valid_iou_list.append(valid_iou)\n",
        "\n",
        "    valid_iou_avg = np.mean(valid_iou_list)\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}] - Train IoU: {train_iou:.4f} - Validation IoU: {valid_iou_avg:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}