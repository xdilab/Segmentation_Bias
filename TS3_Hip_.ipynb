{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e2a8f75-885e-4744-a376-7cdfa90ed3b8",
      "metadata": {
        "id": "8e2a8f75-885e-4744-a376-7cdfa90ed3b8",
        "outputId": "03d2e975-5ca7-4b8a-f4db-c69f0a85c08b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydicom in ./lib/python3.10/site-packages (2.4.4)\n",
            "Requirement already satisfied: nibabel in ./lib/python3.10/site-packages (5.2.0)\n",
            "Requirement already satisfied: numpy in ./lib/python3.10/site-packages (1.26.4)\n",
            "Requirement already satisfied: torch in ./lib/python3.10/site-packages (2.2.0)\n",
            "Requirement already satisfied: torchvision in ./lib/python3.10/site-packages (0.17.0)\n",
            "Requirement already satisfied: segmentation-models-pytorch in ./lib/python3.10/site-packages (0.3.3)\n",
            "Requirement already satisfied: scikit-learn in ./lib/python3.10/site-packages (1.4.0)\n",
            "Requirement already satisfied: packaging>=17 in ./lib/python3.10/site-packages (from nibabel) (23.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in ./lib/python3.10/site-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in ./lib/python3.10/site-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: filelock in ./lib/python3.10/site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: fsspec in ./lib/python3.10/site-packages (from torch) (2024.2.0)\n",
            "Requirement already satisfied: triton==2.2.0 in ./lib/python3.10/site-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: networkx in ./lib/python3.10/site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in ./lib/python3.10/site-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: sympy in ./lib/python3.10/site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
            "Requirement already satisfied: requests in ./lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./lib/python3.10/site-packages (from torchvision) (10.2.0)\n",
            "Requirement already satisfied: timm==0.9.2 in ./lib/python3.10/site-packages (from segmentation-models-pytorch) (0.9.2)\n",
            "Requirement already satisfied: pretrainedmodels==0.7.4 in ./lib/python3.10/site-packages (from segmentation-models-pytorch) (0.7.4)\n",
            "Requirement already satisfied: efficientnet-pytorch==0.7.1 in ./lib/python3.10/site-packages (from segmentation-models-pytorch) (0.7.1)\n",
            "Requirement already satisfied: tqdm in ./lib/python3.10/site-packages (from segmentation-models-pytorch) (4.66.2)\n",
            "Requirement already satisfied: munch in ./lib/python3.10/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.0.0)\n",
            "Requirement already satisfied: safetensors in ./lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.2)\n",
            "Requirement already satisfied: huggingface-hub in ./lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.20.3)\n",
            "Requirement already satisfied: pyyaml in ./lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in ./lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in ./lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./lib/python3.10/site-packages (from requests->torchvision) (2.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./lib/python3.10/site-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./lib/python3.10/site-packages (from requests->torchvision) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in ./lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pydicom nibabel numpy torch torchvision segmentation-models-pytorch scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cff11e2e-e8bb-4b04-9c4e-07abcab6c406",
      "metadata": {
        "id": "cff11e2e-e8bb-4b04-9c4e-07abcab6c406",
        "outputId": "ebe4f433-cd6c-4550-8f7f-20393dd71cf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: albumentations in ./lib/python3.10/site-packages (1.3.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in ./lib/python3.10/site-packages (from albumentations) (1.12.0)\n",
            "Requirement already satisfied: qudida>=0.0.4 in ./lib/python3.10/site-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: numpy>=1.11.1 in ./lib/python3.10/site-packages (from albumentations) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in ./lib/python3.10/site-packages (from albumentations) (4.9.0.80)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in ./lib/python3.10/site-packages (from albumentations) (0.22.0)\n",
            "Requirement already satisfied: PyYAML in ./lib/python3.10/site-packages (from albumentations) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions in ./lib/python3.10/site-packages (from qudida>=0.0.4->albumentations) (4.9.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in ./lib/python3.10/site-packages (from qudida>=0.0.4->albumentations) (1.4.0)\n",
            "Requirement already satisfied: networkx>=2.8 in ./lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (3.2.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in ./lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (2024.2.12)\n",
            "Requirement already satisfied: packaging>=21 in ./lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (23.2)\n",
            "Requirement already satisfied: pillow>=9.0.1 in ./lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (10.2.0)\n",
            "Requirement already satisfied: imageio>=2.27 in ./lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (2.34.0)\n",
            "Requirement already satisfied: lazy_loader>=0.3 in ./lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (0.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./lib/python3.10/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in ./lib/python3.10/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.2.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4acce50-1f26-4dcf-86b0-40213c91354b",
      "metadata": {
        "id": "f4acce50-1f26-4dcf-86b0-40213c91354b",
        "outputId": "ac75b17b-e766-44d0-cff8-9c1e7c863e48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in ./lib/python3.10/site-packages (2.2.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./lib/python3.10/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./lib/python3.10/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in ./lib/python3.10/site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./lib/python3.10/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in ./lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1410b91-d9a5-406a-99ed-32b806471ff7",
      "metadata": {
        "id": "d1410b91-d9a5-406a-99ed-32b806471ff7",
        "outputId": "1dc0c997-fbab-4e99-ad41-8ff7d7fb0373"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher Epoch [1/70], Train IoU: 0.0776\n",
            "Teacher Epoch [2/70], Train IoU: 0.1162\n",
            "Teacher Epoch [3/70], Train IoU: 0.1585\n",
            "Teacher Epoch [4/70], Train IoU: 0.2013\n",
            "Teacher Epoch [5/70], Train IoU: 0.2422\n",
            "Teacher Epoch [6/70], Train IoU: 0.2808\n",
            "Teacher Epoch [7/70], Train IoU: 0.3185\n",
            "Teacher Epoch [8/70], Train IoU: 0.3543\n",
            "Teacher Epoch [9/70], Train IoU: 0.3865\n",
            "Teacher Epoch [10/70], Train IoU: 0.4178\n",
            "Teacher Epoch [11/70], Train IoU: 0.4490\n",
            "Teacher Epoch [12/70], Train IoU: 0.4779\n",
            "Teacher Epoch [13/70], Train IoU: 0.5048\n",
            "Teacher Epoch [14/70], Train IoU: 0.5298\n",
            "Teacher Epoch [15/70], Train IoU: 0.5514\n",
            "Teacher Epoch [16/70], Train IoU: 0.5708\n",
            "Teacher Epoch [17/70], Train IoU: 0.5897\n",
            "Teacher Epoch [18/70], Train IoU: 0.6075\n",
            "Teacher Epoch [19/70], Train IoU: 0.6241\n",
            "Teacher Epoch [20/70], Train IoU: 0.6397\n",
            "Teacher Epoch [21/70], Train IoU: 0.6537\n",
            "Teacher Epoch [22/70], Train IoU: 0.6671\n",
            "Teacher Epoch [23/70], Train IoU: 0.6792\n",
            "Teacher Epoch [24/70], Train IoU: 0.6902\n",
            "Teacher Epoch [25/70], Train IoU: 0.6997\n",
            "Teacher Epoch [26/70], Train IoU: 0.7085\n",
            "Teacher Epoch [27/70], Train IoU: 0.7171\n",
            "Teacher Epoch [28/70], Train IoU: 0.7254\n",
            "Teacher Epoch [29/70], Train IoU: 0.7335\n",
            "Teacher Epoch [30/70], Train IoU: 0.7417\n",
            "Teacher Epoch [31/70], Train IoU: 0.7492\n",
            "Teacher Epoch [32/70], Train IoU: 0.7563\n",
            "Teacher Epoch [33/70], Train IoU: 0.7630\n",
            "Teacher Epoch [34/70], Train IoU: 0.7701\n",
            "Teacher Epoch [35/70], Train IoU: 0.7767\n",
            "Teacher Epoch [36/70], Train IoU: 0.7828\n",
            "Teacher Epoch [37/70], Train IoU: 0.7887\n",
            "Teacher Epoch [38/70], Train IoU: 0.7947\n",
            "Teacher Epoch [39/70], Train IoU: 0.8003\n",
            "Teacher Epoch [40/70], Train IoU: 0.8057\n",
            "Teacher Epoch [41/70], Train IoU: 0.8108\n",
            "Teacher Epoch [42/70], Train IoU: 0.8159\n",
            "Teacher Epoch [43/70], Train IoU: 0.8209\n",
            "Teacher Epoch [44/70], Train IoU: 0.8259\n",
            "Teacher Epoch [45/70], Train IoU: 0.8307\n",
            "Teacher Epoch [46/70], Train IoU: 0.8351\n",
            "Teacher Epoch [47/70], Train IoU: 0.8392\n",
            "Teacher Epoch [48/70], Train IoU: 0.8434\n",
            "Teacher Epoch [49/70], Train IoU: 0.8480\n",
            "Teacher Epoch [50/70], Train IoU: 0.8523\n",
            "Teacher Epoch [51/70], Train IoU: 0.8559\n",
            "Teacher Epoch [52/70], Train IoU: 0.8589\n",
            "Teacher Epoch [53/70], Train IoU: 0.8629\n",
            "Teacher Epoch [54/70], Train IoU: 0.8642\n",
            "Teacher Epoch [55/70], Train IoU: 0.8685\n",
            "Teacher Epoch [56/70], Train IoU: 0.8700\n",
            "Teacher Epoch [57/70], Train IoU: 0.8741\n",
            "Teacher Epoch [58/70], Train IoU: 0.8774\n",
            "Teacher Epoch [59/70], Train IoU: 0.8787\n",
            "Teacher Epoch [60/70], Train IoU: 0.8819\n",
            "Teacher Epoch [61/70], Train IoU: 0.8851\n",
            "Teacher Epoch [62/70], Train IoU: 0.8868\n",
            "Teacher Epoch [63/70], Train IoU: 0.8892\n",
            "Teacher Epoch [64/70], Train IoU: 0.8924\n",
            "Teacher Epoch [65/70], Train IoU: 0.8937\n",
            "Teacher Epoch [66/70], Train IoU: 0.8957\n",
            "Teacher Epoch [67/70], Train IoU: 0.8977\n",
            "Teacher Epoch [68/70], Train IoU: 0.8996\n",
            "Teacher Epoch [69/70], Train IoU: 0.9011\n",
            "Teacher Epoch [70/70], Train IoU: 0.9037\n",
            "Student Epoch [1/100, Train IoU: 0.0362\n",
            "Student Epoch [2/100, Train IoU: 0.0527\n",
            "Student Epoch [3/100, Train IoU: 0.0671\n",
            "Student Epoch [4/100, Train IoU: 0.0827\n",
            "Student Epoch [5/100, Train IoU: 0.1007\n",
            "Student Epoch [6/100, Train IoU: 0.1176\n",
            "Student Epoch [7/100, Train IoU: 0.1332\n",
            "Student Epoch [8/100, Train IoU: 0.1498\n",
            "Student Epoch [9/100, Train IoU: 0.1677\n",
            "Student Epoch [10/100, Train IoU: 0.1852\n",
            "Student Epoch [11/100, Train IoU: 0.2034\n",
            "Student Epoch [12/100, Train IoU: 0.2218\n",
            "Student Epoch [13/100, Train IoU: 0.2403\n",
            "Student Epoch [14/100, Train IoU: 0.2598\n",
            "Student Epoch [15/100, Train IoU: 0.2783\n",
            "Student Epoch [16/100, Train IoU: 0.2974\n",
            "Student Epoch [17/100, Train IoU: 0.3170\n",
            "Student Epoch [18/100, Train IoU: 0.3372\n",
            "Student Epoch [19/100, Train IoU: 0.3569\n",
            "Student Epoch [20/100, Train IoU: 0.3758\n",
            "Student Epoch [21/100, Train IoU: 0.3935\n",
            "Student Epoch [22/100, Train IoU: 0.4104\n",
            "Student Epoch [23/100, Train IoU: 0.4274\n",
            "Student Epoch [24/100, Train IoU: 0.4434\n",
            "Student Epoch [25/100, Train IoU: 0.4585\n",
            "Student Epoch [26/100, Train IoU: 0.4727\n",
            "Student Epoch [27/100, Train IoU: 0.4871\n",
            "Student Epoch [28/100, Train IoU: 0.5021\n",
            "Student Epoch [29/100, Train IoU: 0.5176\n",
            "Student Epoch [30/100, Train IoU: 0.5327\n",
            "Student Epoch [31/100, Train IoU: 0.5471\n",
            "Student Epoch [32/100, Train IoU: 0.5605\n",
            "Student Epoch [33/100, Train IoU: 0.5745\n",
            "Student Epoch [34/100, Train IoU: 0.5880\n",
            "Student Epoch [35/100, Train IoU: 0.6013\n",
            "Student Epoch [36/100, Train IoU: 0.6144\n",
            "Student Epoch [37/100, Train IoU: 0.6270\n",
            "Student Epoch [38/100, Train IoU: 0.6386\n",
            "Student Epoch [39/100, Train IoU: 0.6499\n",
            "Student Epoch [40/100, Train IoU: 0.6612\n",
            "Student Epoch [41/100, Train IoU: 0.6720\n",
            "Student Epoch [42/100, Train IoU: 0.6826\n",
            "Student Epoch [43/100, Train IoU: 0.6920\n",
            "Student Epoch [44/100, Train IoU: 0.7020\n",
            "Student Epoch [45/100, Train IoU: 0.7110\n",
            "Student Epoch [46/100, Train IoU: 0.7197\n",
            "Student Epoch [47/100, Train IoU: 0.7280\n",
            "Student Epoch [48/100, Train IoU: 0.7360\n",
            "Student Epoch [49/100, Train IoU: 0.7436\n",
            "Student Epoch [50/100, Train IoU: 0.7511\n",
            "Student Epoch [51/100, Train IoU: 0.7590\n",
            "Student Epoch [52/100, Train IoU: 0.7656\n",
            "Student Epoch [53/100, Train IoU: 0.7727\n",
            "Student Epoch [54/100, Train IoU: 0.7795\n",
            "Student Epoch [55/100, Train IoU: 0.7862\n",
            "Student Epoch [56/100, Train IoU: 0.7929\n",
            "Student Epoch [57/100, Train IoU: 0.7992\n",
            "Student Epoch [58/100, Train IoU: 0.8051\n",
            "Student Epoch [59/100, Train IoU: 0.8114\n",
            "Student Epoch [60/100, Train IoU: 0.8171\n",
            "Student Epoch [61/100, Train IoU: 0.8226\n",
            "Student Epoch [62/100, Train IoU: 0.8279\n",
            "Student Epoch [63/100, Train IoU: 0.8329\n",
            "Student Epoch [64/100, Train IoU: 0.8380\n",
            "Student Epoch [65/100, Train IoU: 0.8431\n",
            "Student Epoch [66/100, Train IoU: 0.8476\n",
            "Student Epoch [67/100, Train IoU: 0.8527\n",
            "Student Epoch [68/100, Train IoU: 0.8566\n",
            "Student Epoch [69/100, Train IoU: 0.8615\n",
            "Student Epoch [70/100, Train IoU: 0.8653\n",
            "Student Epoch [71/100, Train IoU: 0.8698\n",
            "Student Epoch [72/100, Train IoU: 0.8734\n",
            "Student Epoch [73/100, Train IoU: 0.8777\n",
            "Student Epoch [74/100, Train IoU: 0.8800\n",
            "Student Epoch [75/100, Train IoU: 0.8843\n",
            "Student Epoch [76/100, Train IoU: 0.8864\n",
            "Student Epoch [77/100, Train IoU: 0.8910\n",
            "Student Epoch [78/100, Train IoU: 0.8931\n",
            "Student Epoch [79/100, Train IoU: 0.8973\n",
            "Student Epoch [80/100, Train IoU: 0.8994\n",
            "Student Epoch [81/100, Train IoU: 0.9040\n",
            "Student Epoch [82/100, Train IoU: 0.9058\n",
            "Student Epoch [83/100, Train IoU: 0.9084\n",
            "Student Epoch [84/100, Train IoU: 0.9117\n",
            "Student Epoch [85/100, Train IoU: 0.9135\n",
            "Student Epoch [86/100, Train IoU: 0.9164\n",
            "Student Epoch [87/100, Train IoU: 0.9184\n",
            "Student Epoch [88/100, Train IoU: 0.9199\n",
            "Student Epoch [89/100, Train IoU: 0.9215\n",
            "Student Epoch [90/100, Train IoU: 0.9236\n",
            "Student Epoch [91/100, Train IoU: 0.9252\n",
            "Student Epoch [92/100, Train IoU: 0.9269\n",
            "Student Epoch [93/100, Train IoU: 0.9284\n",
            "Student Epoch [94/100, Train IoU: 0.9295\n",
            "Student Epoch [95/100, Train IoU: 0.9314\n",
            "Student Epoch [96/100, Train IoU: 0.9324\n",
            "Student Epoch [97/100, Train IoU: 0.9333\n",
            "Student Epoch [98/100, Train IoU: 0.9346\n",
            "Student Epoch [99/100, Train IoU: 0.9354\n",
            "Student Epoch [100/100, Train IoU: 0.9365\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import nibabel as nib\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import random\n",
        "import segmentation_models_pytorch as smp\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from scipy.ndimage import zoom\n",
        "from sklearn.metrics import jaccard_score\n",
        "import matplotlib.pyplot as plt\n",
        "from operator import itemgetter\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "num_classes = 7\n",
        "batch_size = 8\n",
        "img_root = \"/home/ealam/JHIR_Hip_Knee_Datasets/Hip/Images\"\n",
        "mask_root = \"/home/ealam/JHIR_Hip_Knee_Datasets/Hip/Annotations\"\n",
        "metadata_path = \"/home/ealam/JHIR_Hip_Knee_Datasets/Hip/segmentation_with_racegender.csv\"\n",
        "test_augmentations = A.Compose([\n",
        "    A.Resize(height=256, width=256),\n",
        "    A.Normalize(mean=(0.485,), std=(0.229,)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "class MulticlassHipSegmentationDataset(Dataset):\n",
        "    def __init__(self, img_root, mask_root, metadata_df, paired_files, num_classes, transforms=None, preprocessing=None):\n",
        "        self.img_root = img_root\n",
        "        self.mask_root = mask_root\n",
        "        self.metadata_df = metadata_df\n",
        "        self.paired_files = paired_files\n",
        "        self.num_classes = num_classes\n",
        "        self.transforms = transforms\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paired_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name, mask_name = self.paired_files[idx]\n",
        "\n",
        "        dicom_image = pydicom.dcmread(os.path.join(self.img_root, img_name))\n",
        "        image = dicom_image.pixel_array.astype(np.float32)\n",
        "        annotation = nib.load(os.path.join(self.mask_root, mask_name))\n",
        "        annotation_data = annotation.get_fdata()\n",
        "        if len(annotation_data.shape) == 3:\n",
        "            annotation_data = annotation_data[:, :, 0]\n",
        "\n",
        "        annotation_data = self.calculate_flipped_rotated_mask(annotation_data)\n",
        "\n",
        "        if annotation_data.ndim > 2 and annotation_data.shape[-1] != 1:\n",
        "            raise ValueError('Mask has multiple channels')\n",
        "\n",
        "        if image.shape != annotation_data.shape:\n",
        "            zoom_factors = np.array(image.shape) / np.array(annotation_data.shape)\n",
        "            annotation_data = zoom(annotation_data, zoom_factors, order=0)\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            transformed = self.transforms(image=image, mask=annotation_data)\n",
        "            image = transformed[\"image\"]\n",
        "            annotation_data = transformed[\"mask\"]\n",
        "\n",
        "        annotation_data_onehot = self.one_hot_encode(annotation_data)\n",
        "\n",
        "        if self.preprocessing is not None:\n",
        "            transformed = self.preprocessing(image=image, mask=annotation_data_onehot)\n",
        "            image = transformed[\"image\"]\n",
        "            annotation_data_onehot = transformed[\"mask\"]\n",
        "\n",
        "        return image, annotation_data_onehot\n",
        "\n",
        "    def one_hot_encode(self, mask):\n",
        "        one_hot_mask = np.zeros((self.num_classes, *mask.shape), dtype=np.float32)\n",
        "        for class_idx in range(self.num_classes):\n",
        "            one_hot_mask[class_idx][mask == class_idx] = 1.0\n",
        "        return one_hot_mask\n",
        "\n",
        "    def calculate_flipped_rotated_mask(self, mask):\n",
        "        rotated_mask = cv2.rotate(mask, cv2.ROTATE_90_CLOCKWISE)\n",
        "        flipped_rotated_mask = cv2.flip(rotated_mask, 1)\n",
        "        return flipped_rotated_mask\n",
        "\n",
        "metadata_df = pd.read_csv(metadata_path)\n",
        "\n",
        "image_files = sorted(os.listdir(img_root))\n",
        "mask_files = sorted(os.listdir(mask_root))\n",
        "\n",
        "# Pair files based on imageid\n",
        "paired_files = []\n",
        "for img_file in image_files:\n",
        "    img_id = os.path.splitext(img_file)[0]\n",
        "    mask_file = f\"{img_id}.nii.gz\"\n",
        "    if mask_file in mask_files:\n",
        "        paired_files.append((img_file, mask_file))\n",
        "\n",
        "random.shuffle(paired_files)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_size = int(0.7 * len(paired_files))\n",
        "valid_size = int(0.2 * len(paired_files))\n",
        "test_size = len(paired_files) - train_size - valid_size\n",
        "\n",
        "train_pairs = paired_files[:train_size]\n",
        "valid_pairs = paired_files[train_size:train_size + valid_size]\n",
        "test_pairs = paired_files[train_size + valid_size:]\n",
        "\n",
        "train_set = MulticlassHipSegmentationDataset(\n",
        "    img_root, mask_root, metadata_df, train_pairs, num_classes,\n",
        "    transforms=test_augmentations\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# Teacher model training\n",
        "teacher_model = smp.Unet(\n",
        "    encoder_name=\"resnet18\",\n",
        "    encoder_weights=\"imagenet\",\n",
        "    in_channels=1,\n",
        "    classes=num_classes,\n",
        ")\n",
        "teacher_model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(teacher_model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "tepoch = 70\n",
        "for epoch in range(tepoch):\n",
        "    teacher_model.train()\n",
        "    train_iou_list = []\n",
        "    for images, masks in train_loader:\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = teacher_model(images)\n",
        "        predicted_masks = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        train_iou = jaccard_score(\n",
        "            masks.argmax(dim=1).cpu().numpy().flatten(),\n",
        "            predicted_masks.cpu().numpy().flatten(),\n",
        "            average='micro'\n",
        "        )\n",
        "        train_iou_list.append(train_iou)\n",
        "\n",
        "        loss = criterion(outputs, masks.argmax(dim=1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    mean_train_iou = np.mean(train_iou_list)\n",
        "    print(f\"Teacher Epoch [{epoch+1}/{tepoch}], Train IoU: {mean_train_iou:.4f}\")\n",
        "\n",
        "# Save the trained teacher model\n",
        "torch.save(teacher_model.state_dict(), \"trained_teacher_model.pth\")\n",
        "\n",
        "# Student model training using knowledge distillation\n",
        "teacher_model.load_state_dict(torch.load(\"trained_teacher_model.pth\"))\n",
        "teacher_model.to(device)\n",
        "\n",
        "student_model = smp.Unet(\n",
        "    encoder_name=\"resnet18\",\n",
        "    encoder_weights=\"imagenet\",\n",
        "    in_channels=1,\n",
        "    classes=num_classes,\n",
        ")\n",
        "student_model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(student_model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "\n",
        "iou_diffs = []\n",
        "sepoch=100\n",
        "for epoch in range(sepoch):\n",
        "    student_model.train()\n",
        "    iou_scores = []\n",
        "    for images, masks in train_loader:\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = student_model(images)\n",
        "        loss = criterion(outputs, masks.argmax(dim=1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate IoU for teacher and student\n",
        "        with torch.no_grad():\n",
        "            teacher_outputs = teacher_model(images)\n",
        "            teacher_predicted_masks = torch.argmax(teacher_outputs, dim=1)\n",
        "            teacher_iou = jaccard_score(\n",
        "                masks.argmax(dim=1).cpu().numpy().flatten(),\n",
        "                teacher_predicted_masks.cpu().numpy().flatten(),\n",
        "                average='micro'\n",
        "            )\n",
        "\n",
        "            student_predicted_masks = torch.argmax(outputs, dim=1)\n",
        "            student_iou = jaccard_score(\n",
        "                masks.argmax(dim=1).cpu().numpy().flatten(),\n",
        "                student_predicted_masks.cpu().numpy().flatten(),\n",
        "                average='micro'\n",
        "            )\n",
        "\n",
        "            # Calculate the difference and store it\n",
        "            iou_diff = teacher_iou - student_iou\n",
        "            iou_diffs.append((iou_diff, images, masks, student_predicted_masks))\n",
        "\n",
        "            iou_scores.append(student_iou)\n",
        "\n",
        "    avg_iou = np.mean(iou_scores)\n",
        "    print(f\"Student Epoch [{epoch+1}/{sepoch}, Train IoU: {avg_iou:.4f}\")\n",
        "\n",
        "# Sort the dataset based on IoU difference\n",
        "iou_diffs.sort(key=itemgetter(0))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}