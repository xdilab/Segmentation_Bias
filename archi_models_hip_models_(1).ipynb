{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4000413",
      "metadata": {
        "id": "f4000413",
        "outputId": "cadbebe0-1aa6-4752-fffb-fbaa35fa3614"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pydicom in /home/ealam/.local/lib/python3.10/site-packages (2.4.4)\n",
            "Requirement already satisfied: nibabel in /home/ealam/.local/lib/python3.10/site-packages (5.2.0)\n",
            "Requirement already satisfied: numpy in /home/ealam/.local/lib/python3.10/site-packages (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/lib/python3/dist-packages (2.3.1)\n",
            "Requirement already satisfied: torchvision in /usr/lib/python3/dist-packages (0.18.1)\n",
            "Requirement already satisfied: segmentation-models-pytorch in /home/ealam/.local/lib/python3.10/site-packages (0.3.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/lib/python3/dist-packages (0.23.2)\n",
            "Requirement already satisfied: packaging>=17 in /home/ealam/.local/lib/python3.10/site-packages (from nibabel) (24.1)\n",
            "Requirement already satisfied: efficientnet-pytorch==0.7.1 in /home/ealam/.local/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.7.1)\n",
            "Requirement already satisfied: pillow in /usr/lib/python3/dist-packages (from segmentation-models-pytorch) (9.0.1)\n",
            "Requirement already satisfied: tqdm in /home/ealam/.local/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.66.4)\n",
            "Requirement already satisfied: pretrainedmodels==0.7.4 in /home/ealam/.local/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.7.4)\n",
            "Requirement already satisfied: timm==0.9.2 in /home/ealam/.local/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.9.2)\n",
            "Requirement already satisfied: munch in /home/ealam/.local/lib/python3.10/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.0.0)\n",
            "Requirement already satisfied: safetensors in /home/ealam/.local/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.2)\n",
            "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (5.4.1)\n",
            "Requirement already satisfied: huggingface-hub in /home/ealam/.local/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.23.5)\n",
            "Requirement already satisfied: requests in /home/ealam/.local/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2.32.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/ealam/.local/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2024.2.0)\n",
            "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/lib/python3/dist-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (4.9.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ealam/.local/lib/python3.10/site-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2020.6.20)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ealam/.local/lib/python3.10/site-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/ealam/.local/lib/python3.10/site-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pydicom nibabel numpy torch torchvision segmentation-models-pytorch scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7875cbff",
      "metadata": {
        "id": "7875cbff",
        "outputId": "11352f3e-2c51-4b61-cc80-97e1761e52db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: albumentations in /home/ealam/.local/lib/python3.10/site-packages (1.3.1)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /home/ealam/.local/lib/python3.10/site-packages (from albumentations) (4.10.0.84)\n",
            "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from albumentations) (5.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /home/ealam/.local/lib/python3.10/site-packages (from albumentations) (1.26.4)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /home/ealam/.local/lib/python3.10/site-packages (from albumentations) (0.20.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/lib/python3/dist-packages (from albumentations) (1.8.0)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /home/ealam/.local/lib/python3.10/site-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/lib/python3/dist-packages (from qudida>=0.0.4->albumentations) (4.9.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/lib/python3/dist-packages (from qudida>=0.0.4->albumentations) (0.23.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /home/ealam/.local/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (2024.1.30)\n",
            "Requirement already satisfied: pillow>=9.0.1 in /usr/lib/python3/dist-packages (from scikit-image>=0.16.1->albumentations) (9.0.1)\n",
            "Requirement already satisfied: networkx>=2.8 in /home/ealam/.local/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (3.2.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /home/ealam/.local/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (1.6.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /home/ealam/.local/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (0.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/ealam/.local/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (24.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /home/ealam/.local/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (2.5.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ffb08bf",
      "metadata": {
        "id": "2ffb08bf",
        "outputId": "306f657c-138a-41b6-861b-82b88d0db5db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pandas in /usr/lib/python3/dist-packages (1.3.5)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa476d1f",
      "metadata": {
        "id": "aa476d1f",
        "outputId": "3e249552-0fb9-4651-b6c8-4c2e04aaebc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: opencv-python in /home/ealam/.local/lib/python3.10/site-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /home/ealam/.local/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b68c279",
      "metadata": {
        "id": "0b68c279",
        "outputId": "3ba11fa8-52d5-4cec-8f69-2b8dafa9eca2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training U-Net++ ..\n",
            "Epoch [1/100] - Train IoU: 0.0598 - Validation IoU: 0.0230\n",
            "Epoch [2/100] - Train IoU: 0.1014 - Validation IoU: 0.0476\n",
            "Epoch [3/100] - Train IoU: 0.1478 - Validation IoU: 0.1551\n",
            "Epoch [4/100] - Train IoU: 0.1827 - Validation IoU: 0.1813\n",
            "Epoch [5/100] - Train IoU: 0.2550 - Validation IoU: 0.2145\n",
            "Epoch [6/100] - Train IoU: 0.2893 - Validation IoU: 0.2580\n",
            "Epoch [7/100] - Train IoU: 0.3284 - Validation IoU: 0.2994\n",
            "Epoch [8/100] - Train IoU: 0.3981 - Validation IoU: 0.3358\n",
            "Epoch [9/100] - Train IoU: 0.4370 - Validation IoU: 0.3420\n",
            "Epoch [10/100] - Train IoU: 0.4905 - Validation IoU: 0.3795\n",
            "Epoch [11/100] - Train IoU: 0.5195 - Validation IoU: 0.4407\n",
            "Epoch [12/100] - Train IoU: 0.5749 - Validation IoU: 0.5048\n",
            "Epoch [13/100] - Train IoU: 0.5954 - Validation IoU: 0.5585\n",
            "Epoch [14/100] - Train IoU: 0.6409 - Validation IoU: 0.6014\n",
            "Epoch [15/100] - Train IoU: 0.6727 - Validation IoU: 0.6511\n",
            "Epoch [16/100] - Train IoU: 0.6929 - Validation IoU: 0.6862\n",
            "Epoch [17/100] - Train IoU: 0.7569 - Validation IoU: 0.7215\n",
            "Epoch [18/100] - Train IoU: 0.7582 - Validation IoU: 0.7662\n",
            "Epoch [19/100] - Train IoU: 0.8080 - Validation IoU: 0.7972\n",
            "Epoch [20/100] - Train IoU: 0.8012 - Validation IoU: 0.8290\n",
            "Epoch [21/100] - Train IoU: 0.8494 - Validation IoU: 0.8448\n",
            "Epoch [22/100] - Train IoU: 0.8665 - Validation IoU: 0.8557\n",
            "Epoch [23/100] - Train IoU: 0.8738 - Validation IoU: 0.8728\n",
            "Epoch [24/100] - Train IoU: 0.8735 - Validation IoU: 0.8678\n",
            "Epoch [25/100] - Train IoU: 0.8823 - Validation IoU: 0.8622\n",
            "Epoch [26/100] - Train IoU: 0.8962 - Validation IoU: 0.8769\n",
            "Epoch [27/100] - Train IoU: 0.9089 - Validation IoU: 0.8892\n",
            "Epoch [28/100] - Train IoU: 0.8983 - Validation IoU: 0.8994\n",
            "Epoch [29/100] - Train IoU: 0.9122 - Validation IoU: 0.8978\n",
            "Epoch [30/100] - Train IoU: 0.9203 - Validation IoU: 0.8988\n",
            "Epoch [31/100] - Train IoU: 0.9256 - Validation IoU: 0.9068\n",
            "Epoch [32/100] - Train IoU: 0.9244 - Validation IoU: 0.9111\n",
            "Epoch [33/100] - Train IoU: 0.9277 - Validation IoU: 0.9137\n",
            "Epoch [34/100] - Train IoU: 0.9312 - Validation IoU: 0.9178\n",
            "Epoch [35/100] - Train IoU: 0.9315 - Validation IoU: 0.9211\n",
            "Epoch [36/100] - Train IoU: 0.9322 - Validation IoU: 0.9232\n",
            "Epoch [37/100] - Train IoU: 0.9414 - Validation IoU: 0.9203\n",
            "Epoch [38/100] - Train IoU: 0.9410 - Validation IoU: 0.9278\n",
            "Epoch [39/100] - Train IoU: 0.9449 - Validation IoU: 0.9302\n",
            "Epoch [40/100] - Train IoU: 0.9398 - Validation IoU: 0.9316\n",
            "Epoch [41/100] - Train IoU: 0.9448 - Validation IoU: 0.9331\n",
            "Epoch [42/100] - Train IoU: 0.9478 - Validation IoU: 0.9344\n",
            "Epoch [43/100] - Train IoU: 0.9517 - Validation IoU: 0.9354\n",
            "Epoch [44/100] - Train IoU: 0.9561 - Validation IoU: 0.9346\n",
            "Epoch [45/100] - Train IoU: 0.9543 - Validation IoU: 0.9361\n",
            "Epoch [46/100] - Train IoU: 0.9530 - Validation IoU: 0.9378\n",
            "Epoch [47/100] - Train IoU: 0.9574 - Validation IoU: 0.9376\n",
            "Epoch [48/100] - Train IoU: 0.9599 - Validation IoU: 0.9428\n",
            "Epoch [49/100] - Train IoU: 0.9553 - Validation IoU: 0.9430\n",
            "Epoch [50/100] - Train IoU: 0.9598 - Validation IoU: 0.9396\n",
            "Epoch [51/100] - Train IoU: 0.9613 - Validation IoU: 0.9420\n",
            "Epoch [52/100] - Train IoU: 0.9598 - Validation IoU: 0.9426\n",
            "Epoch [53/100] - Train IoU: 0.9606 - Validation IoU: 0.9429\n",
            "Epoch [54/100] - Train IoU: 0.9623 - Validation IoU: 0.9423\n",
            "Epoch [55/100] - Train IoU: 0.9634 - Validation IoU: 0.9437\n",
            "Epoch [56/100] - Train IoU: 0.9656 - Validation IoU: 0.9451\n",
            "Epoch [57/100] - Train IoU: 0.9661 - Validation IoU: 0.9447\n",
            "Epoch [58/100] - Train IoU: 0.9678 - Validation IoU: 0.9454\n",
            "Epoch [59/100] - Train IoU: 0.9602 - Validation IoU: 0.9452\n",
            "Epoch [60/100] - Train IoU: 0.9643 - Validation IoU: 0.9464\n",
            "Epoch [61/100] - Train IoU: 0.9651 - Validation IoU: 0.9447\n",
            "Epoch [62/100] - Train IoU: 0.9687 - Validation IoU: 0.9443\n",
            "Epoch [63/100] - Train IoU: 0.9675 - Validation IoU: 0.9488\n",
            "Epoch [64/100] - Train IoU: 0.9688 - Validation IoU: 0.9493\n",
            "Epoch [65/100] - Train IoU: 0.9692 - Validation IoU: 0.9482\n",
            "Epoch [66/100] - Train IoU: 0.9716 - Validation IoU: 0.9474\n",
            "Epoch [67/100] - Train IoU: 0.9711 - Validation IoU: 0.9496\n",
            "Epoch [68/100] - Train IoU: 0.9705 - Validation IoU: 0.9504\n",
            "Epoch [69/100] - Train IoU: 0.9734 - Validation IoU: 0.9487\n",
            "Epoch [70/100] - Train IoU: 0.9738 - Validation IoU: 0.9488\n",
            "Epoch [71/100] - Train IoU: 0.9711 - Validation IoU: 0.9495\n",
            "Epoch [72/100] - Train IoU: 0.9727 - Validation IoU: 0.9497\n",
            "Epoch [73/100] - Train IoU: 0.9731 - Validation IoU: 0.9484\n",
            "Epoch [74/100] - Train IoU: 0.9728 - Validation IoU: 0.9500\n",
            "Epoch [75/100] - Train IoU: 0.9713 - Validation IoU: 0.9517\n",
            "Epoch [76/100] - Train IoU: 0.9728 - Validation IoU: 0.9499\n",
            "Epoch [77/100] - Train IoU: 0.9752 - Validation IoU: 0.9503\n",
            "Epoch [78/100] - Train IoU: 0.9735 - Validation IoU: 0.9499\n",
            "Epoch [79/100] - Train IoU: 0.9735 - Validation IoU: 0.9498\n",
            "Epoch [80/100] - Train IoU: 0.9754 - Validation IoU: 0.9491\n",
            "Epoch [81/100] - Train IoU: 0.9752 - Validation IoU: 0.9512\n",
            "Epoch [82/100] - Train IoU: 0.9734 - Validation IoU: 0.9522\n",
            "Epoch [83/100] - Train IoU: 0.9754 - Validation IoU: 0.9517\n",
            "Epoch [84/100] - Train IoU: 0.9761 - Validation IoU: 0.9498\n",
            "Epoch [85/100] - Train IoU: 0.9748 - Validation IoU: 0.9506\n",
            "Epoch [86/100] - Train IoU: 0.9748 - Validation IoU: 0.9493\n",
            "Epoch [87/100] - Train IoU: 0.9763 - Validation IoU: 0.9517\n",
            "Epoch [88/100] - Train IoU: 0.9792 - Validation IoU: 0.9500\n",
            "Epoch [89/100] - Train IoU: 0.9795 - Validation IoU: 0.9492\n",
            "Epoch [90/100] - Train IoU: 0.9773 - Validation IoU: 0.9508\n",
            "Epoch [91/100] - Train IoU: 0.9783 - Validation IoU: 0.9517\n",
            "Epoch [92/100] - Train IoU: 0.9787 - Validation IoU: 0.9524\n",
            "Epoch [93/100] - Train IoU: 0.9787 - Validation IoU: 0.9518\n",
            "Epoch [94/100] - Train IoU: 0.9807 - Validation IoU: 0.9516\n",
            "Epoch [95/100] - Train IoU: 0.9804 - Validation IoU: 0.9529\n",
            "Epoch [96/100] - Train IoU: 0.9788 - Validation IoU: 0.9517\n",
            "Epoch [97/100] - Train IoU: 0.9800 - Validation IoU: 0.9508\n",
            "Epoch [98/100] - Train IoU: 0.9807 - Validation IoU: 0.9519\n",
            "Epoch [99/100] - Train IoU: 0.9806 - Validation IoU: 0.9531\n",
            "Epoch [100/100] - Train IoU: 0.9805 - Validation IoU: 0.9524\n",
            "Model saved successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import nibabel as nib\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import random\n",
        "import segmentation_models_pytorch as smp\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "num_classes = 7\n",
        "batch_size = 4\n",
        "img_root = \"/home/ealam/JHIR_Hip_Knee_Datasets/Hip/Images\"\n",
        "mask_root = \"/home/ealam/JHIR_Hip_Knee_Datasets/Hip/Annotations\"\n",
        "metadata_path = \"/home/ealam/JHIR_Hip_Knee_Datasets/Hip/segmentation_with_racegender.csv\"\n",
        "\n",
        "\n",
        "test_augmentations = A.Compose([\n",
        "    A.Resize(height=512, width=512),\n",
        "    A.Normalize(mean=(0.485, 0.485, 0.485), std=(0.229, 0.229, 0.229)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "class MulticlassHipSegmentationDataset(Dataset):\n",
        "    def __init__(self, img_root, mask_root, metadata_df, paired_files, num_classes, transforms=None, preprocessing=None):\n",
        "        self.img_root = img_root\n",
        "        self.mask_root = mask_root\n",
        "        self.metadata_df = metadata_df\n",
        "        self.paired_files = paired_files\n",
        "        self.num_classes = num_classes\n",
        "        self.transforms = transforms\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paired_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_file, mask_file = self.paired_files[idx]\n",
        "        if not os.path.exists(os.path.join(self.mask_root, mask_file)):\n",
        "            return None\n",
        "\n",
        "        dicom_image = pydicom.dcmread(os.path.join(self.img_root, image_file))\n",
        "        image = dicom_image.pixel_array.astype(np.float32)\n",
        "        image = cv2.resize(image, (512, 512))\n",
        "\n",
        "\n",
        "        image = np.stack([image] * 3, axis=-1)\n",
        "\n",
        "        annotation = nib.load(os.path.join(self.mask_root, mask_file))\n",
        "        annotation_data = annotation.get_fdata()\n",
        "        if len(annotation_data.shape) == 3:\n",
        "            annotation_data = annotation_data[:, :, 0]\n",
        "\n",
        "        annotation_data = self.calculate_flipped_rotated_mask(annotation_data)\n",
        "        annotation_data = cv2.resize(annotation_data,\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            transformed = self.transforms(image=image, mask=annotation_data)\n",
        "            image = transformed[\"image\"]\n",
        "            annotation_data = transformed[\"mask\"]\n",
        "\n",
        "        annotation_data_onehot = self.one_hot_encode(annotation_data)\n",
        "\n",
        "        if self.preprocessing is not None:\n",
        "            transformed = self.preprocessing(image=image, mask=annotation_data_onehot)\n",
        "            image = transformed[\"image\"]\n",
        "            annotation_data_onehot = transformed[\"mask\"]\n",
        "\n",
        "        patient_id = int(float(image_file.split(\".\")[0]))\n",
        "        racegender_info = self.metadata_df.loc[self.metadata_df['id'] == patient_id]['racegender'].values\n",
        "        racegender = racegender_info[0] if racegender_info.size > 0 else 'Unknown'\n",
        "\n",
        "        return image, annotation_data_onehot, racegender\n",
        "\n",
        "    def one_hot_encode(self, mask):\n",
        "        one_hot_mask = np.zeros((self.num_classes, *mask.shape), dtype=np.float32)\n",
        "        for class_idx in range(self.num_classes):\n",
        "            one_hot_mask[class_idx][mask == class_idx] = 1.0\n",
        "        return one_hot_mask\n",
        "\n",
        "    def calculate_flipped_rotated_mask(self, mask):\n",
        "        rotated_mask = cv2.rotate(mask, cv2.ROTATE_90_CLOCKWISE)\n",
        "        flipped_rotated_mask = cv2.flip(rotated_mask, 1)\n",
        "        return flipped_rotated_mask\n",
        "\n",
        "metadata_df = pd.read_csv(metadata_path)\n",
        "\n",
        "image_files = sorted(os.listdir(img_root))\n",
        "mask_files = sorted(os.listdir(mask_root))\n",
        "\n",
        "paired_files = []\n",
        "\n",
        "for image_file in image_files:\n",
        "    image_id = os.path.splitext(image_file)[0]\n",
        "    mask_file = f\"{image_id}.nii.gz\"\n",
        "    if mask_file in mask_files:\n",
        "        paired_files.append((image_file, mask_file))\n",
        "\n",
        "random.shuffle(paired_files)\n",
        "\n",
        "train_size = int(0.7 * len(paired_files))\n",
        "valid_size = int(0.1 * len(paired_files))\n",
        "test_size = len(paired_files) - train_size - valid_size\n",
        "\n",
        "train_pairs = paired_files[:train_size]\n",
        "valid_pairs = paired_files[train_size:train_size + valid_size]\n",
        "test_pairs = paired_files[train_size + valid_size:]\n",
        "\n",
        "train_set = MulticlassHipSegmentationDataset(\n",
        "    img_root, mask_root, metadata_df, train_pairs, num_classes,\n",
        "    transforms=test_augmentations\n",
        ")\n",
        "\n",
        "def train_unetplusplus_model(num_epochs=100, encoder_name=\"resnet18\"):\n",
        "\n",
        "    model = smp.UnetPlusPlus(\n",
        "        encoder_name=encoder_name,\n",
        "        encoder_weights=\"imagenet\",\n",
        "        in_channels=3,\n",
        "        classes=num_classes,\n",
        "    )\n",
        "\n",
        "    device = torch.device(\"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    valid_set = MulticlassHipSegmentationDataset(\n",
        "        img_root, mask_root, metadata_df, valid_pairs, num_classes,\n",
        "        transforms=test_augmentations\n",
        "    )\n",
        "\n",
        "    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "        model.train()\n",
        "        train_iou_list = []\n",
        "\n",
        "        for batch_idx, (images, masks, racegender) in enumerate(train_loader):\n",
        "            if images is None:\n",
        "                continue\n",
        "\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "\n",
        "            predicted_masks = torch.argmax(outputs, dim=1)\n",
        "            loss = criterion(outputs, masks.argmax(dim=1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_iou = jaccard_score(\n",
        "                masks.argmax(dim=1).cpu().numpy().flatten(),\n",
        "                predicted_masks.cpu().numpy().flatten(),\n",
        "                average='micro'\n",
        "            )\n",
        "            train_iou_list.append(train_iou)\n",
        "\n",
        "        model.eval()\n",
        "        valid_iou_list = []\n",
        "\n",
        "        for batch_idx, (images, masks, racegender) in enumerate(valid_loader):\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(images)\n",
        "            predicted_masks = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            valid_iou = jaccard_score(\n",
        "                masks.argmax(dim=1).cpu().numpy().flatten(),\n",
        "                predicted_masks.cpu().numpy().flatten(),\n",
        "                average='micro'\n",
        "            )\n",
        "\n",
        "            valid_iou_list.append(valid_iou)\n",
        "\n",
        "        train_iou_avg = np.mean(train_iou_list)\n",
        "        valid_iou_avg = np.mean(valid_iou_list)\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}] - Train IoU: {train_iou_avg:.4f} - Validation IoU: {valid_iou_avg:.4f}\")\n",
        "\n",
        "\n",
        "    torch.save(model.state_dict(), 'unetplusplus_model_hip_init.pth')\n",
        "\n",
        "\n",
        "    test_set = MulticlassHipSegmentationDataset(\n",
        "        img_root, mask_root, metadata_df, test_pairs, num_classes,\n",
        "        transforms=test_augmentations\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    model.eval()\n",
        "    test_iou_list = []\n",
        "\n",
        "    for batch_idx, (images, masks, racegender) in enumerate(test_loader):\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(images)\n",
        "        predicted_masks = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        test_iou = jaccard_score(\n",
        "            masks.argmax(dim=1).cpu().numpy().flatten(),\n",
        "            predicted_masks.cpu().numpy().flatten(),\n",
        "            average='micro'\n",
        "        )\n",
        "\n",
        "        test_iou_list.append(test_iou)\n",
        "\n",
        "    test_iou_avg = np.mean(test_iou_list)\n",
        "\n",
        "    print(\"Model saved successfully.\")\n",
        "\n",
        "\n",
        "print(\"Training U-Net++ ..\")\n",
        "train_unetplusplus_model(encoder_name=\"resnet18\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65005146",
      "metadata": {
        "id": "65005146",
        "outputId": "f9110ee6-4036-4a0f-ec29-39596e7fd766"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training LinkNet ..\n",
            "Epoch [1/100] - Train IoU: 0.0806 - Validation IoU: 0.0288\n",
            "Epoch [2/100] - Train IoU: 0.0883 - Validation IoU: 0.0280\n",
            "Epoch [3/100] - Train IoU: 0.1000 - Validation IoU: 0.0278\n",
            "Epoch [4/100] - Train IoU: 0.1096 - Validation IoU: 0.0271\n",
            "Epoch [5/100] - Train IoU: 0.1252 - Validation IoU: 0.0259\n",
            "Epoch [6/100] - Train IoU: 0.1236 - Validation IoU: 0.0254\n",
            "Epoch [7/100] - Train IoU: 0.1465 - Validation IoU: 0.0327\n",
            "Epoch [8/100] - Train IoU: 0.1529 - Validation IoU: 0.0499\n",
            "Epoch [9/100] - Train IoU: 0.1578 - Validation IoU: 0.0848\n",
            "Epoch [10/100] - Train IoU: 0.1657 - Validation IoU: 0.1133\n",
            "Epoch [11/100] - Train IoU: 0.1711 - Validation IoU: 0.1286\n",
            "Epoch [12/100] - Train IoU: 0.1696 - Validation IoU: 0.1349\n",
            "Epoch [13/100] - Train IoU: 0.1826 - Validation IoU: 0.1446\n",
            "Epoch [14/100] - Train IoU: 0.1891 - Validation IoU: 0.1507\n",
            "Epoch [15/100] - Train IoU: 0.1878 - Validation IoU: 0.1548\n",
            "Epoch [16/100] - Train IoU: 0.1843 - Validation IoU: 0.1546\n",
            "Epoch [17/100] - Train IoU: 0.2108 - Validation IoU: 0.1519\n",
            "Epoch [18/100] - Train IoU: 0.2037 - Validation IoU: 0.1582\n",
            "Epoch [19/100] - Train IoU: 0.2068 - Validation IoU: 0.1634\n",
            "Epoch [20/100] - Train IoU: 0.2099 - Validation IoU: 0.1710\n",
            "Epoch [21/100] - Train IoU: 0.2156 - Validation IoU: 0.1782\n",
            "Epoch [22/100] - Train IoU: 0.2191 - Validation IoU: 0.1822\n",
            "Epoch [23/100] - Train IoU: 0.2233 - Validation IoU: 0.1908\n",
            "Epoch [24/100] - Train IoU: 0.2414 - Validation IoU: 0.1966\n",
            "Epoch [25/100] - Train IoU: 0.2522 - Validation IoU: 0.1957\n",
            "Epoch [26/100] - Train IoU: 0.2572 - Validation IoU: 0.2125\n",
            "Epoch [27/100] - Train IoU: 0.2572 - Validation IoU: 0.2226\n",
            "Epoch [28/100] - Train IoU: 0.2703 - Validation IoU: 0.2338\n",
            "Epoch [29/100] - Train IoU: 0.2913 - Validation IoU: 0.2490\n",
            "Epoch [30/100] - Train IoU: 0.2969 - Validation IoU: 0.2598\n",
            "Epoch [31/100] - Train IoU: 0.3014 - Validation IoU: 0.2709\n",
            "Epoch [32/100] - Train IoU: 0.3246 - Validation IoU: 0.2838\n",
            "Epoch [33/100] - Train IoU: 0.3475 - Validation IoU: 0.3005\n",
            "Epoch [34/100] - Train IoU: 0.3447 - Validation IoU: 0.3132\n",
            "Epoch [35/100] - Train IoU: 0.3720 - Validation IoU: 0.3325\n",
            "Epoch [36/100] - Train IoU: 0.3796 - Validation IoU: 0.3610\n",
            "Epoch [37/100] - Train IoU: 0.3897 - Validation IoU: 0.3779\n",
            "Epoch [38/100] - Train IoU: 0.4009 - Validation IoU: 0.3903\n",
            "Epoch [39/100] - Train IoU: 0.4217 - Validation IoU: 0.4073\n",
            "Epoch [40/100] - Train IoU: 0.4509 - Validation IoU: 0.4293\n",
            "Epoch [41/100] - Train IoU: 0.4674 - Validation IoU: 0.4658\n",
            "Epoch [42/100] - Train IoU: 0.4951 - Validation IoU: 0.4987\n",
            "Epoch [43/100] - Train IoU: 0.5184 - Validation IoU: 0.4972\n",
            "Epoch [44/100] - Train IoU: 0.5312 - Validation IoU: 0.5269\n",
            "Epoch [45/100] - Train IoU: 0.5556 - Validation IoU: 0.5633\n",
            "Epoch [46/100] - Train IoU: 0.5720 - Validation IoU: 0.5736\n",
            "Epoch [47/100] - Train IoU: 0.5753 - Validation IoU: 0.5807\n",
            "Epoch [48/100] - Train IoU: 0.5954 - Validation IoU: 0.5814\n",
            "Epoch [49/100] - Train IoU: 0.6053 - Validation IoU: 0.6069\n",
            "Epoch [50/100] - Train IoU: 0.6143 - Validation IoU: 0.6222\n",
            "Epoch [51/100] - Train IoU: 0.6164 - Validation IoU: 0.6252\n",
            "Epoch [52/100] - Train IoU: 0.6325 - Validation IoU: 0.6117\n",
            "Epoch [53/100] - Train IoU: 0.6297 - Validation IoU: 0.6193\n",
            "Epoch [54/100] - Train IoU: 0.6377 - Validation IoU: 0.6329\n",
            "Epoch [55/100] - Train IoU: 0.6497 - Validation IoU: 0.6326\n",
            "Epoch [56/100] - Train IoU: 0.6537 - Validation IoU: 0.6384\n",
            "Epoch [57/100] - Train IoU: 0.6733 - Validation IoU: 0.6415\n",
            "Epoch [58/100] - Train IoU: 0.6712 - Validation IoU: 0.6548\n",
            "Epoch [59/100] - Train IoU: 0.6748 - Validation IoU: 0.6655\n",
            "Epoch [60/100] - Train IoU: 0.6709 - Validation IoU: 0.6748\n",
            "Epoch [61/100] - Train IoU: 0.6829 - Validation IoU: 0.6718\n",
            "Epoch [62/100] - Train IoU: 0.6889 - Validation IoU: 0.6754\n",
            "Epoch [63/100] - Train IoU: 0.6859 - Validation IoU: 0.6848\n",
            "Epoch [64/100] - Train IoU: 0.7002 - Validation IoU: 0.6879\n",
            "Epoch [65/100] - Train IoU: 0.7119 - Validation IoU: 0.6930\n",
            "Epoch [66/100] - Train IoU: 0.7114 - Validation IoU: 0.6963\n",
            "Epoch [67/100] - Train IoU: 0.6979 - Validation IoU: 0.7049\n",
            "Epoch [68/100] - Train IoU: 0.7280 - Validation IoU: 0.7070\n",
            "Epoch [69/100] - Train IoU: 0.7220 - Validation IoU: 0.7062\n",
            "Epoch [70/100] - Train IoU: 0.7284 - Validation IoU: 0.7108\n",
            "Epoch [71/100] - Train IoU: 0.7367 - Validation IoU: 0.7123\n",
            "Epoch [72/100] - Train IoU: 0.7327 - Validation IoU: 0.7180\n",
            "Epoch [73/100] - Train IoU: 0.7285 - Validation IoU: 0.7272\n",
            "Epoch [74/100] - Train IoU: 0.7557 - Validation IoU: 0.7309\n",
            "Epoch [75/100] - Train IoU: 0.7473 - Validation IoU: 0.7326\n",
            "Epoch [76/100] - Train IoU: 0.7562 - Validation IoU: 0.7342\n",
            "Epoch [77/100] - Train IoU: 0.7483 - Validation IoU: 0.7303\n",
            "Epoch [78/100] - Train IoU: 0.7588 - Validation IoU: 0.7319\n",
            "Epoch [79/100] - Train IoU: 0.7676 - Validation IoU: 0.7431\n",
            "Epoch [80/100] - Train IoU: 0.7733 - Validation IoU: 0.7499\n",
            "Epoch [81/100] - Train IoU: 0.7782 - Validation IoU: 0.7559\n",
            "Epoch [82/100] - Train IoU: 0.7861 - Validation IoU: 0.7588\n",
            "Epoch [83/100] - Train IoU: 0.7887 - Validation IoU: 0.7651\n",
            "Epoch [84/100] - Train IoU: 0.8031 - Validation IoU: 0.7710\n",
            "Epoch [85/100] - Train IoU: 0.7945 - Validation IoU: 0.7742\n",
            "Epoch [86/100] - Train IoU: 0.8057 - Validation IoU: 0.7779\n",
            "Epoch [87/100] - Train IoU: 0.8146 - Validation IoU: 0.7961\n",
            "Epoch [88/100] - Train IoU: 0.7945 - Validation IoU: 0.8056\n",
            "Epoch [89/100] - Train IoU: 0.8362 - Validation IoU: 0.8073\n",
            "Epoch [90/100] - Train IoU: 0.8351 - Validation IoU: 0.8072\n",
            "Epoch [91/100] - Train IoU: 0.8515 - Validation IoU: 0.8207\n",
            "Epoch [92/100] - Train IoU: 0.8650 - Validation IoU: 0.8386\n",
            "Epoch [93/100] - Train IoU: 0.8697 - Validation IoU: 0.8420\n",
            "Epoch [94/100] - Train IoU: 0.8739 - Validation IoU: 0.8451\n",
            "Epoch [95/100] - Train IoU: 0.8837 - Validation IoU: 0.8517\n",
            "Epoch [96/100] - Train IoU: 0.8852 - Validation IoU: 0.8586\n",
            "Epoch [97/100] - Train IoU: 0.8839 - Validation IoU: 0.8550\n",
            "Epoch [98/100] - Train IoU: 0.8946 - Validation IoU: 0.8607\n",
            "Epoch [99/100] - Train IoU: 0.8810 - Validation IoU: 0.8702\n",
            "Epoch [100/100] - Train IoU: 0.9028 - Validation IoU: 0.8707\n",
            "Model saved successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import nibabel as nib\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import random\n",
        "import segmentation_models_pytorch as smp\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "num_classes = 7\n",
        "batch_size = 4\n",
        "img_root = \"/home/ealam/JHIR_Hip_Knee_Datasets/Hip/Images\"\n",
        "mask_root = \"/home/ealam/JHIR_Hip_Knee_Datasets/Hip/Annotations\"\n",
        "metadata_path = \"/home/ealam/JHIR_Hip_Knee_Datasets/Hip/segmentation_with_racegender.csv\"\n",
        "\n",
        "\n",
        "test_augmentations = A.Compose([\n",
        "    A.Resize(height=512, width=512),\n",
        "    A.Normalize(mean=(0.485, 0.485, 0.485), std=(0.229, 0.229, 0.229)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "class MulticlassHipSegmentationDataset(Dataset):\n",
        "    def __init__(self, img_root, mask_root, metadata_df, paired_files, num_classes, transforms=None, preprocessing=None):\n",
        "        self.img_root = img_root\n",
        "        self.mask_root = mask_root\n",
        "        self.metadata_df = metadata_df\n",
        "        self.paired_files = paired_files\n",
        "        self.num_classes = num_classes\n",
        "        self.transforms = transforms\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paired_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_file, mask_file = self.paired_files[idx]\n",
        "        if not os.path.exists(os.path.join(self.mask_root, mask_file)):\n",
        "            return None\n",
        "\n",
        "        dicom_image = pydicom.dcmread(os.path.join(self.img_root, image_file))\n",
        "        image = dicom_image.pixel_array.astype(np.float32)\n",
        "        image = cv2.resize(image, (512, 512))\n",
        "\n",
        "\n",
        "        image = np.stack([image] * 3, axis=-1)\n",
        "\n",
        "        annotation = nib.load(os.path.join(self.mask_root, mask_file))\n",
        "        annotation_data = annotation.get_fdata()\n",
        "        if len(annotation_data.shape) == 3:\n",
        "            annotation_data = annotation_data[:, :, 0]\n",
        "\n",
        "        annotation_data = self.calculate_flipped_rotated_mask(annotation_data)\n",
        "        annotation_data = cv2.resize(annotation_data, (512, 512))\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            transformed = self.transforms(image=image, mask=annotation_data)\n",
        "            image = transformed[\"image\"]\n",
        "            annotation_data = transformed[\"mask\"]\n",
        "\n",
        "        annotation_data_onehot = self.one_hot_encode(annotation_data)\n",
        "\n",
        "        if self.preprocessing is not None:\n",
        "            transformed = self.preprocessing(image=image, mask=annotation_data_onehot)\n",
        "            image = transformed[\"image\"]\n",
        "            annotation_data_onehot = transformed[\"mask\"]\n",
        "\n",
        "        patient_id = int(float(image_file.split(\".\")[0]))\n",
        "        racegender_info = self.metadata_df.loc[self.metadata_df['id'] == patient_id]['racegender'].values\n",
        "        racegender = racegender_info[0] if racegender_info.size > 0 else 'Unknown'\n",
        "\n",
        "        return image, annotation_data_onehot, racegender\n",
        "\n",
        "    def one_hot_encode(self, mask):\n",
        "        one_hot_mask = np.zeros((self.num_classes, *mask.shape), dtype=np.float32)\n",
        "        for class_idx in range(self.num_classes):\n",
        "            one_hot_mask[class_idx][mask == class_idx] = 1.0\n",
        "        return one_hot_mask\n",
        "\n",
        "    def calculate_flipped_rotated_mask(self, mask):\n",
        "        rotated_mask = cv2.rotate(mask, cv2.ROTATE_90_CLOCKWISE)\n",
        "        flipped_rotated_mask = cv2.flip(rotated_mask, 1)\n",
        "        return flipped_rotated_mask\n",
        "\n",
        "metadata_df = pd.read_csv(metadata_path)\n",
        "\n",
        "image_files = sorted(os.listdir(img_root))\n",
        "mask_files = sorted(os.listdir(mask_root))\n",
        "\n",
        "paired_files = []\n",
        "\n",
        "for image_file in image_files:\n",
        "    image_id = os.path.splitext(image_file)[0]\n",
        "    mask_file = f\"{image_id}.nii.gz\"\n",
        "    if mask_file in mask_files:\n",
        "        paired_files.append((image_file, mask_file))\n",
        "\n",
        "random.shuffle(paired_files)\n",
        "\n",
        "train_size = int(0.7 * len(paired_files))\n",
        "valid_size = int(0.1 * len(paired_files))\n",
        "test_size = len(paired_files) - train_size - valid_size\n",
        "\n",
        "train_pairs = paired_files[:train_size]\n",
        "valid_pairs = paired_files[train_size:train_size + valid_size]\n",
        "test_pairs = paired_files[train_size + valid_size:]\n",
        "\n",
        "train_set = MulticlassHipSegmentationDataset(\n",
        "    img_root, mask_root, metadata_df, train_pairs, num_classes,\n",
        "    transforms=test_augmentations\n",
        ")\n",
        "\n",
        "def train_linknet_model(num_epochs=100, encoder_name=\"resnet18\"):\n",
        "\n",
        "    model = smp.Linknet(\n",
        "        encoder_name=encoder_name,\n",
        "        encoder_weights=\"imagenet\",\n",
        "        in_channels=3,\n",
        "        classes=num_classes,\n",
        "    )\n",
        "\n",
        "    device = torch.device(\"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    valid_set = MulticlassHipSegmentationDataset(\n",
        "        img_root, mask_root, metadata_df, valid_pairs, num_classes,\n",
        "        transforms=test_augmentations\n",
        "    )\n",
        "\n",
        "    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "        model.train()\n",
        "        train_iou_list = []\n",
        "\n",
        "        for batch_idx, (images, masks, racegender) in enumerate(train_loader):\n",
        "            if images is None:\n",
        "                continue\n",
        "\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "\n",
        "            predicted_masks = torch.argmax(outputs, dim=1)\n",
        "            loss = criterion(outputs, masks.argmax(dim=1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_iou = jaccard_score(\n",
        "                masks.argmax(dim=1).cpu().numpy().flatten(),\n",
        "                predicted_masks.cpu().numpy().flatten(),\n",
        "                average='micro'\n",
        "            )\n",
        "            train_iou_list.append(train_iou)\n",
        "\n",
        "        model.eval()\n",
        "        valid_iou_list = []\n",
        "\n",
        "        for batch_idx, (images, masks, racegender) in enumerate(valid_loader):\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(images)\n",
        "            predicted_masks = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            valid_iou = jaccard_score(\n",
        "                masks.argmax(dim=1).cpu().numpy().flatten(),\n",
        "                predicted_masks.cpu().numpy().flatten(),\n",
        "                average='micro'\n",
        "            )\n",
        "\n",
        "            valid_iou_list.append(valid_iou)\n",
        "\n",
        "        train_iou_avg = np.mean(train_iou_list)\n",
        "        valid_iou_avg = np.mean(valid_iou_list)\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}] - Train IoU: {train_iou_avg:.4f} - Validation IoU: {valid_iou_avg:.4f}\")\n",
        "\n",
        "\n",
        "    torch.save(model.state_dict(), 'linknet_model_Hip_init.pth')\n",
        "\n",
        "\n",
        "    test_set = MulticlassHipSegmentationDataset(\n",
        "        img_root, mask_root, metadata_df, test_pairs, num_classes,\n",
        "        transforms=test_augmentations\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    model.eval()\n",
        "    test_iou_list = []\n",
        "\n",
        "    for batch_idx, (images, masks, racegender) in enumerate(test_loader):\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(images)\n",
        "        predicted_masks = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        test_iou = jaccard_score(\n",
        "            masks.argmax(dim=1).cpu().numpy().flatten(),\n",
        "            predicted_masks.cpu().numpy().flatten(),\n",
        "            average='micro'\n",
        "        )\n",
        "\n",
        "        test_iou_list.append(test_iou)\n",
        "\n",
        "    test_iou_avg = np.mean(test_iou_list)\n",
        "\n",
        "\n",
        "    print(\"Model saved successfully.\")\n",
        "\n",
        "\n",
        "print(\"Training LinkNet ..\")\n",
        "train_linknet_model(encoder_name=\"resnet18\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd4b3b6c",
      "metadata": {
        "id": "fd4b3b6c",
        "outputId": "31a11ac5-069d-4e65-c9d5-f052f5f8e603"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training PSPNet ..\n",
            "Epoch [1/100] - Train IoU: 0.1508 - Validation IoU: 0.4623\n",
            "Epoch [2/100] - Train IoU: 0.3613 - Validation IoU: 0.5369\n",
            "Epoch [3/100] - Train IoU: 0.4850 - Validation IoU: 0.5392\n",
            "Epoch [4/100] - Train IoU: 0.5449 - Validation IoU: 0.5393\n",
            "Epoch [5/100] - Train IoU: 0.5661 - Validation IoU: 0.5393\n",
            "Epoch [6/100] - Train IoU: 0.5691 - Validation IoU: 0.5393\n",
            "Epoch [7/100] - Train IoU: 0.5418 - Validation IoU: 0.5393\n",
            "Epoch [8/100] - Train IoU: 0.5772 - Validation IoU: 0.5393\n",
            "Epoch [9/100] - Train IoU: 0.5477 - Validation IoU: 0.5393\n",
            "Epoch [10/100] - Train IoU: 0.5676 - Validation IoU: 0.5397\n",
            "Epoch [11/100] - Train IoU: 0.5873 - Validation IoU: 0.5408\n",
            "Epoch [12/100] - Train IoU: 0.6059 - Validation IoU: 0.5448\n",
            "Epoch [13/100] - Train IoU: 0.6239 - Validation IoU: 0.5568\n",
            "Epoch [14/100] - Train IoU: 0.6347 - Validation IoU: 0.5769\n",
            "Epoch [15/100] - Train IoU: 0.6617 - Validation IoU: 0.6027\n",
            "Epoch [16/100] - Train IoU: 0.6584 - Validation IoU: 0.6296\n",
            "Epoch [17/100] - Train IoU: 0.6484 - Validation IoU: 0.6328\n",
            "Epoch [18/100] - Train IoU: 0.6778 - Validation IoU: 0.6405\n",
            "Epoch [19/100] - Train IoU: 0.6609 - Validation IoU: 0.6194\n",
            "Epoch [20/100] - Train IoU: 0.6668 - Validation IoU: 0.6379\n",
            "Epoch [21/100] - Train IoU: 0.6872 - Validation IoU: 0.7032\n",
            "Epoch [22/100] - Train IoU: 0.6949 - Validation IoU: 0.7058\n",
            "Epoch [23/100] - Train IoU: 0.7070 - Validation IoU: 0.7021\n",
            "Epoch [24/100] - Train IoU: 0.7514 - Validation IoU: 0.7170\n",
            "Epoch [25/100] - Train IoU: 0.7193 - Validation IoU: 0.7443\n",
            "Epoch [26/100] - Train IoU: 0.7542 - Validation IoU: 0.7617\n",
            "Epoch [27/100] - Train IoU: 0.7784 - Validation IoU: 0.7739\n",
            "Epoch [28/100] - Train IoU: 0.7706 - Validation IoU: 0.7479\n",
            "Epoch [29/100] - Train IoU: 0.7449 - Validation IoU: 0.7542\n",
            "Epoch [30/100] - Train IoU: 0.7895 - Validation IoU: 0.7374\n",
            "Epoch [31/100] - Train IoU: 0.7710 - Validation IoU: 0.7570\n",
            "Epoch [32/100] - Train IoU: 0.7773 - Validation IoU: 0.7796\n",
            "Epoch [33/100] - Train IoU: 0.7931 - Validation IoU: 0.7797\n",
            "Epoch [34/100] - Train IoU: 0.7494 - Validation IoU: 0.7878\n",
            "Epoch [35/100] - Train IoU: 0.8212 - Validation IoU: 0.7921\n",
            "Epoch [36/100] - Train IoU: 0.7954 - Validation IoU: 0.7943\n",
            "Epoch [37/100] - Train IoU: 0.7864 - Validation IoU: 0.8086\n",
            "Epoch [38/100] - Train IoU: 0.8109 - Validation IoU: 0.8144\n",
            "Epoch [39/100] - Train IoU: 0.8108 - Validation IoU: 0.8209\n",
            "Epoch [40/100] - Train IoU: 0.8198 - Validation IoU: 0.8277\n",
            "Epoch [41/100] - Train IoU: 0.8234 - Validation IoU: 0.8281\n",
            "Epoch [42/100] - Train IoU: 0.8308 - Validation IoU: 0.8228\n",
            "Epoch [43/100] - Train IoU: 0.8469 - Validation IoU: 0.8239\n",
            "Epoch [44/100] - Train IoU: 0.8029 - Validation IoU: 0.8081\n",
            "Epoch [45/100] - Train IoU: 0.8217 - Validation IoU: 0.8124\n",
            "Epoch [46/100] - Train IoU: 0.8506 - Validation IoU: 0.8282\n",
            "Epoch [47/100] - Train IoU: 0.8558 - Validation IoU: 0.8432\n",
            "Epoch [48/100] - Train IoU: 0.8494 - Validation IoU: 0.8467\n",
            "Epoch [49/100] - Train IoU: 0.8423 - Validation IoU: 0.8258\n",
            "Epoch [50/100] - Train IoU: 0.8657 - Validation IoU: 0.8190\n",
            "Epoch [51/100] - Train IoU: 0.8565 - Validation IoU: 0.8332\n",
            "Epoch [52/100] - Train IoU: 0.8484 - Validation IoU: 0.8508\n",
            "Epoch [53/100] - Train IoU: 0.8519 - Validation IoU: 0.8532\n",
            "Epoch [54/100] - Train IoU: 0.8745 - Validation IoU: 0.8543\n",
            "Epoch [55/100] - Train IoU: 0.8739 - Validation IoU: 0.8509\n",
            "Epoch [56/100] - Train IoU: 0.8761 - Validation IoU: 0.8586\n",
            "Epoch [57/100] - Train IoU: 0.8700 - Validation IoU: 0.8614\n",
            "Epoch [58/100] - Train IoU: 0.8853 - Validation IoU: 0.8644\n",
            "Epoch [59/100] - Train IoU: 0.8770 - Validation IoU: 0.8652\n",
            "Epoch [60/100] - Train IoU: 0.8765 - Validation IoU: 0.8728\n",
            "Epoch [61/100] - Train IoU: 0.8750 - Validation IoU: 0.8766\n",
            "Epoch [62/100] - Train IoU: 0.8772 - Validation IoU: 0.8836\n",
            "Epoch [63/100] - Train IoU: 0.8879 - Validation IoU: 0.8757\n",
            "Epoch [64/100] - Train IoU: 0.8831 - Validation IoU: 0.8545\n",
            "Epoch [65/100] - Train IoU: 0.8782 - Validation IoU: 0.8365\n",
            "Epoch [66/100] - Train IoU: 0.8919 - Validation IoU: 0.8633\n",
            "Epoch [67/100] - Train IoU: 0.8869 - Validation IoU: 0.8639\n",
            "Epoch [68/100] - Train IoU: 0.9020 - Validation IoU: 0.8685\n",
            "Epoch [69/100] - Train IoU: 0.8964 - Validation IoU: 0.8646\n",
            "Epoch [70/100] - Train IoU: 0.8945 - Validation IoU: 0.8625\n",
            "Epoch [71/100] - Train IoU: 0.8885 - Validation IoU: 0.8517\n",
            "Epoch [72/100] - Train IoU: 0.8985 - Validation IoU: 0.8641\n",
            "Epoch [73/100] - Train IoU: 0.9001 - Validation IoU: 0.8864\n",
            "Epoch [74/100] - Train IoU: 0.8969 - Validation IoU: 0.8986\n",
            "Epoch [75/100] - Train IoU: 0.9066 - Validation IoU: 0.9018\n",
            "Epoch [76/100] - Train IoU: 0.9088 - Validation IoU: 0.8841\n",
            "Epoch [77/100] - Train IoU: 0.9097 - Validation IoU: 0.8735\n",
            "Epoch [78/100] - Train IoU: 0.9043 - Validation IoU: 0.8714\n",
            "Epoch [79/100] - Train IoU: 0.9115 - Validation IoU: 0.8897\n",
            "Epoch [80/100] - Train IoU: 0.9089 - Validation IoU: 0.8930\n",
            "Epoch [81/100] - Train IoU: 0.9147 - Validation IoU: 0.8892\n",
            "Epoch [82/100] - Train IoU: 0.9149 - Validation IoU: 0.8588\n",
            "Epoch [83/100] - Train IoU: 0.9106 - Validation IoU: 0.8009\n",
            "Epoch [84/100] - Train IoU: 0.9135 - Validation IoU: 0.8456\n",
            "Epoch [85/100] - Train IoU: 0.9138 - Validation IoU: 0.8811\n",
            "Epoch [86/100] - Train IoU: 0.9098 - Validation IoU: 0.8944\n",
            "Epoch [87/100] - Train IoU: 0.9052 - Validation IoU: 0.9070\n",
            "Epoch [88/100] - Train IoU: 0.9189 - Validation IoU: 0.9053\n",
            "Epoch [89/100] - Train IoU: 0.9164 - Validation IoU: 0.9168\n",
            "Epoch [90/100] - Train IoU: 0.9256 - Validation IoU: 0.9125\n",
            "Epoch [91/100] - Train IoU: 0.9133 - Validation IoU: 0.9034\n",
            "Epoch [92/100] - Train IoU: 0.9228 - Validation IoU: 0.9015\n",
            "Epoch [93/100] - Train IoU: 0.9251 - Validation IoU: 0.9056\n",
            "Epoch [94/100] - Train IoU: 0.9212 - Validation IoU: 0.9097\n",
            "Epoch [95/100] - Train IoU: 0.9325 - Validation IoU: 0.9132\n",
            "Epoch [96/100] - Train IoU: 0.9259 - Validation IoU: 0.9102\n",
            "Epoch [97/100] - Train IoU: 0.9290 - Validation IoU: 0.9132\n",
            "Epoch [98/100] - Train IoU: 0.9255 - Validation IoU: 0.9164\n",
            "Epoch [99/100] - Train IoU: 0.9237 - Validation IoU: 0.9154\n",
            "Epoch [100/100] - Train IoU: 0.9248 - Validation IoU: 0.9121\n",
            "Model saved successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import nibabel as nib\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import random\n",
        "import segmentation_models_pytorch as smp\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "num_classes = 7\n",
        "batch_size = 4\n",
        "img_root = \"/home/ealam/JHIR_Hip_Knee_Datasets/Hip/Images\"\n",
        "mask_root = \"/home/ealam/JHIR_Hip_Knee_Datasets/Hip/Annotations\"\n",
        "metadata_path = \"/home/ealam/JHIR_Hip_Knee_Datasets/Hip/segmentation_with_racegender.csv\"\n",
        "\n",
        "\n",
        "test_augmentations = A.Compose([\n",
        "    A.Resize(height=512, width=512),\n",
        "    A.Normalize(mean=(0.485, 0.485, 0.485), std=(0.229, 0.229, 0.229)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "class MulticlassHipSegmentationDataset(Dataset):\n",
        "    def __init__(self, img_root, mask_root, metadata_df, paired_files, num_classes, transforms=None, preprocessing=None):\n",
        "        self.img_root = img_root\n",
        "        self.mask_root = mask_root\n",
        "        self.metadata_df = metadata_df\n",
        "        self.paired_files = paired_files\n",
        "        self.num_classes = num_classes\n",
        "        self.transforms = transforms\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paired_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_file, mask_file = self.paired_files[idx]\n",
        "        if not os.path.exists(os.path.join(self.mask_root, mask_file)):\n",
        "            return None\n",
        "\n",
        "        dicom_image = pydicom.dcmread(os.path.join(self.img_root, image_file))\n",
        "        image = dicom_image.pixel_array.astype(np.float32)\n",
        "        image = cv2.resize(image, (512, 512))\n",
        "\n",
        "\n",
        "        image = np.stack([image] * 3, axis=-1)\n",
        "\n",
        "        annotation = nib.load(os.path.join(self.mask_root, mask_file))\n",
        "        annotation_data = annotation.get_fdata()\n",
        "        if len(annotation_data.shape) == 3:\n",
        "            annotation_data = annotation_data[:, :, 0]\n",
        "\n",
        "        annotation_data = self.calculate_flipped_rotated_mask(annotation_data)\n",
        "        annotation_data = cv2.resize(annotation_data, (512, 512))\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            transformed = self.transforms(image=image, mask=annotation_data)\n",
        "            image = transformed[\"image\"]\n",
        "            annotation_data = transformed[\"mask\"]\n",
        "\n",
        "        annotation_data_onehot = self.one_hot_encode(annotation_data)\n",
        "\n",
        "        if self.preprocessing is not None:\n",
        "            transformed = self.preprocessing(image=image, mask=annotation_data_onehot)\n",
        "            image = transformed[\"image\"]\n",
        "            annotation_data_onehot = transformed[\"mask\"]\n",
        "\n",
        "        patient_id = int(float(image_file.split(\".\")[0]))\n",
        "        racegender_info = self.metadata_df.loc[self.metadata_df['id'] == patient_id]['racegender'].values\n",
        "        racegender = racegender_info[0] if racegender_info.size > 0 else 'Unknown'\n",
        "\n",
        "        return image, annotation_data_onehot, racegender\n",
        "\n",
        "    def one_hot_encode(self, mask):\n",
        "        one_hot_mask = np.zeros((self.num_classes, *mask.shape), dtype=np.float32)\n",
        "        for class_idx in range(self.num_classes):\n",
        "            one_hot_mask[class_idx][mask == class_idx] = 1.0\n",
        "        return one_hot_mask\n",
        "\n",
        "    def calculate_flipped_rotated_mask(self, mask):\n",
        "        rotated_mask = cv2.rotate(mask, cv2.ROTATE_90_CLOCKWISE)\n",
        "        flipped_rotated_mask = cv2.flip(rotated_mask, 1)\n",
        "        return flipped_rotated_mask\n",
        "\n",
        "metadata_df = pd.read_csv(metadata_path)\n",
        "\n",
        "image_files = sorted(os.listdir(img_root))\n",
        "mask_files = sorted(os.listdir(mask_root))\n",
        "\n",
        "paired_files = []\n",
        "\n",
        "for image_file in image_files:\n",
        "    image_id = os.path.splitext(image_file)[0]\n",
        "    mask_file = f\"{image_id}.nii.gz\"\n",
        "    if mask_file in mask_files:\n",
        "        paired_files.append((image_file, mask_file))\n",
        "\n",
        "random.shuffle(paired_files)\n",
        "\n",
        "train_size = int(0.7 * len(paired_files))\n",
        "valid_size = int(0.1 * len(paired_files))\n",
        "test_size = len(paired_files) - train_size - valid_size\n",
        "\n",
        "train_pairs = paired_files[:train_size]\n",
        "valid_pairs = paired_files[train_size:train_size + valid_size]\n",
        "test_pairs = paired_files[train_size + valid_size:]\n",
        "\n",
        "train_set = MulticlassHipSegmentationDataset(\n",
        "    img_root, mask_root, metadata_df, train_pairs, num_classes,\n",
        "    transforms=test_augmentations\n",
        ")\n",
        "\n",
        "def train_pspnet_model(num_epochs=100, encoder_name=\"resnet18\"):\n",
        "\n",
        "    model = smp.PSPNet(\n",
        "        encoder_name=encoder_name,\n",
        "        encoder_weights=\"imagenet\",\n",
        "        in_channels=3,\n",
        "        classes=num_classes,\n",
        "    )\n",
        "\n",
        "    device = torch.device(\"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    valid_set = MulticlassHipSegmentationDataset(\n",
        "        img_root, mask_root, metadata_df, valid_pairs, num_classes,\n",
        "        transforms=test_augmentations\n",
        "    )\n",
        "\n",
        "    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "        model.train()\n",
        "        train_iou_list = []\n",
        "\n",
        "        for batch_idx, (images, masks, racegender) in enumerate(train_loader):\n",
        "            if images is None:\n",
        "                continue\n",
        "\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "\n",
        "            predicted_masks = torch.argmax(outputs, dim=1)\n",
        "            loss = criterion(outputs, masks.argmax(dim=1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_iou = jaccard_score(\n",
        "                masks.argmax(dim=1).cpu().numpy().flatten(),\n",
        "                predicted_masks.cpu().numpy().flatten(),\n",
        "                average='micro'\n",
        "            )\n",
        "            train_iou_list.append(train_iou)\n",
        "\n",
        "        model.eval()\n",
        "        valid_iou_list = []\n",
        "\n",
        "        for batch_idx, (images, masks, racegender) in enumerate(valid_loader):\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(images)\n",
        "            predicted_masks = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            valid_iou = jaccard_score(\n",
        "                masks.argmax(dim=1).cpu().numpy().flatten(),\n",
        "                predicted_masks.cpu().numpy().flatten(),\n",
        "                average='micro'\n",
        "            )\n",
        "\n",
        "            valid_iou_list.append(valid_iou)\n",
        "\n",
        "        train_iou_avg = np.mean(train_iou_list)\n",
        "        valid_iou_avg = np.mean(valid_iou_list)\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}] - Train IoU: {train_iou_avg:.4f} - Validation IoU: {valid_iou_avg:.4f}\")\n",
        "\n",
        "\n",
        "    torch.save(model.state_dict(), 'pspnet_model_Hip_init.pth')\n",
        "\n",
        "\n",
        "    test_set = MulticlassHipSegmentationDataset(\n",
        "        img_root, mask_root, metadata_df, test_pairs, num_classes,\n",
        "        transforms=test_augmentations\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    model.eval()\n",
        "    test_iou_list = []\n",
        "\n",
        "    for batch_idx, (images, masks, racegender) in enumerate(test_loader):\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(images)\n",
        "        predicted_masks = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        test_iou = jaccard_score(\n",
        "            masks.argmax(dim=1).cpu().numpy().flatten(),\n",
        "            predicted_masks.cpu().numpy().flatten(),\n",
        "            average='micro'\n",
        "        )\n",
        "\n",
        "        test_iou_list.append(test_iou)\n",
        "\n",
        "    test_iou_avg = np.mean(test_iou_list)\n",
        "\n",
        "    print(\"Model saved successfully.\")\n",
        "\n",
        "\n",
        "print(\"Training PSPNet ..\")\n",
        "train_pspnet_model(encoder_name=\"resnet18\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "584c49a0",
      "metadata": {
        "id": "584c49a0",
        "outputId": "e766a7f4-e9fe-48db-97ec-3bfe7c0bd72d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training FPN ..\n",
            "Epoch [1/100] - Train IoU: 0.1522 - Validation IoU: 0.5233\n",
            "Epoch [2/100] - Train IoU: 0.5325 - Validation IoU: 0.5413\n",
            "Epoch [3/100] - Train IoU: 0.6204 - Validation IoU: 0.5913\n",
            "Epoch [4/100] - Train IoU: 0.6450 - Validation IoU: 0.6005\n",
            "Epoch [5/100] - Train IoU: 0.6962 - Validation IoU: 0.6254\n",
            "Epoch [6/100] - Train IoU: 0.7097 - Validation IoU: 0.6425\n",
            "Epoch [7/100] - Train IoU: 0.7535 - Validation IoU: 0.6429\n",
            "Epoch [8/100] - Train IoU: 0.7635 - Validation IoU: 0.6357\n",
            "Epoch [9/100] - Train IoU: 0.7510 - Validation IoU: 0.6301\n",
            "Epoch [10/100] - Train IoU: 0.7648 - Validation IoU: 0.6507\n",
            "Epoch [11/100] - Train IoU: 0.7853 - Validation IoU: 0.6995\n",
            "Epoch [12/100] - Train IoU: 0.8051 - Validation IoU: 0.7401\n",
            "Epoch [13/100] - Train IoU: 0.7849 - Validation IoU: 0.7454\n",
            "Epoch [14/100] - Train IoU: 0.8163 - Validation IoU: 0.7267\n",
            "Epoch [15/100] - Train IoU: 0.8202 - Validation IoU: 0.7025\n",
            "Epoch [16/100] - Train IoU: 0.8314 - Validation IoU: 0.6999\n",
            "Epoch [17/100] - Train IoU: 0.8151 - Validation IoU: 0.7144\n",
            "Epoch [18/100] - Train IoU: 0.8236 - Validation IoU: 0.7596\n",
            "Epoch [19/100] - Train IoU: 0.8077 - Validation IoU: 0.7986\n",
            "Epoch [20/100] - Train IoU: 0.8496 - Validation IoU: 0.8065\n",
            "Epoch [21/100] - Train IoU: 0.8389 - Validation IoU: 0.8203\n",
            "Epoch [22/100] - Train IoU: 0.8483 - Validation IoU: 0.8338\n",
            "Epoch [23/100] - Train IoU: 0.8566 - Validation IoU: 0.8210\n",
            "Epoch [24/100] - Train IoU: 0.8336 - Validation IoU: 0.7972\n",
            "Epoch [25/100] - Train IoU: 0.8499 - Validation IoU: 0.8012\n",
            "Epoch [26/100] - Train IoU: 0.8711 - Validation IoU: 0.8159\n",
            "Epoch [27/100] - Train IoU: 0.8596 - Validation IoU: 0.8297\n",
            "Epoch [28/100] - Train IoU: 0.8805 - Validation IoU: 0.8396\n",
            "Epoch [29/100] - Train IoU: 0.8751 - Validation IoU: 0.8524\n",
            "Epoch [30/100] - Train IoU: 0.8632 - Validation IoU: 0.8589\n",
            "Epoch [31/100] - Train IoU: 0.8859 - Validation IoU: 0.8769\n",
            "Epoch [32/100] - Train IoU: 0.8768 - Validation IoU: 0.8825\n",
            "Epoch [33/100] - Train IoU: 0.8818 - Validation IoU: 0.8834\n",
            "Epoch [34/100] - Train IoU: 0.8853 - Validation IoU: 0.8749\n",
            "Epoch [35/100] - Train IoU: 0.8931 - Validation IoU: 0.8693\n",
            "Epoch [36/100] - Train IoU: 0.8750 - Validation IoU: 0.8721\n",
            "Epoch [37/100] - Train IoU: 0.8851 - Validation IoU: 0.8703\n",
            "Epoch [38/100] - Train IoU: 0.9003 - Validation IoU: 0.8836\n",
            "Epoch [39/100] - Train IoU: 0.9019 - Validation IoU: 0.8840\n",
            "Epoch [40/100] - Train IoU: 0.9087 - Validation IoU: 0.8885\n",
            "Epoch [41/100] - Train IoU: 0.8967 - Validation IoU: 0.8873\n",
            "Epoch [42/100] - Train IoU: 0.9052 - Validation IoU: 0.8921\n",
            "Epoch [43/100] - Train IoU: 0.9052 - Validation IoU: 0.8995\n",
            "Epoch [44/100] - Train IoU: 0.8989 - Validation IoU: 0.9025\n",
            "Epoch [45/100] - Train IoU: 0.8963 - Validation IoU: 0.8945\n",
            "Epoch [46/100] - Train IoU: 0.8826 - Validation IoU: 0.8748\n",
            "Epoch [47/100] - Train IoU: 0.8762 - Validation IoU: 0.8729\n",
            "Epoch [48/100] - Train IoU: 0.9059 - Validation IoU: 0.8829\n",
            "Epoch [49/100] - Train IoU: 0.9181 - Validation IoU: 0.8942\n",
            "Epoch [50/100] - Train IoU: 0.9079 - Validation IoU: 0.9037\n",
            "Epoch [51/100] - Train IoU: 0.9131 - Validation IoU: 0.9065\n",
            "Epoch [52/100] - Train IoU: 0.9190 - Validation IoU: 0.9006\n",
            "Epoch [53/100] - Train IoU: 0.8949 - Validation IoU: 0.8981\n",
            "Epoch [54/100] - Train IoU: 0.9205 - Validation IoU: 0.9066\n",
            "Epoch [55/100] - Train IoU: 0.8958 - Validation IoU: 0.9088\n",
            "Epoch [56/100] - Train IoU: 0.9207 - Validation IoU: 0.9012\n",
            "Epoch [57/100] - Train IoU: 0.9223 - Validation IoU: 0.9002\n",
            "Epoch [58/100] - Train IoU: 0.9155 - Validation IoU: 0.8983\n",
            "Epoch [59/100] - Train IoU: 0.9192 - Validation IoU: 0.9109\n",
            "Epoch [60/100] - Train IoU: 0.9135 - Validation IoU: 0.9168\n",
            "Epoch [61/100] - Train IoU: 0.9215 - Validation IoU: 0.9128\n",
            "Epoch [62/100] - Train IoU: 0.9270 - Validation IoU: 0.9125\n",
            "Epoch [63/100] - Train IoU: 0.9284 - Validation IoU: 0.9140\n",
            "Epoch [64/100] - Train IoU: 0.9263 - Validation IoU: 0.9114\n",
            "Epoch [65/100] - Train IoU: 0.9299 - Validation IoU: 0.9101\n",
            "Epoch [66/100] - Train IoU: 0.9263 - Validation IoU: 0.9099\n",
            "Epoch [67/100] - Train IoU: 0.9030 - Validation IoU: 0.9112\n",
            "Epoch [68/100] - Train IoU: 0.9343 - Validation IoU: 0.9220\n",
            "Epoch [69/100] - Train IoU: 0.9318 - Validation IoU: 0.9215\n",
            "Epoch [70/100] - Train IoU: 0.9298 - Validation IoU: 0.9159\n",
            "Epoch [71/100] - Train IoU: 0.9349 - Validation IoU: 0.9103\n",
            "Epoch [72/100] - Train IoU: 0.9342 - Validation IoU: 0.9051\n",
            "Epoch [73/100] - Train IoU: 0.9311 - Validation IoU: 0.9067\n",
            "Epoch [74/100] - Train IoU: 0.9378 - Validation IoU: 0.9187\n",
            "Epoch [75/100] - Train IoU: 0.9329 - Validation IoU: 0.9207\n",
            "Epoch [76/100] - Train IoU: 0.9409 - Validation IoU: 0.9153\n",
            "Epoch [77/100] - Train IoU: 0.9434 - Validation IoU: 0.9147\n",
            "Epoch [78/100] - Train IoU: 0.9365 - Validation IoU: 0.9168\n",
            "Epoch [79/100] - Train IoU: 0.9376 - Validation IoU: 0.9145\n",
            "Epoch [80/100] - Train IoU: 0.9300 - Validation IoU: 0.9120\n",
            "Epoch [81/100] - Train IoU: 0.9306 - Validation IoU: 0.9181\n",
            "Epoch [82/100] - Train IoU: 0.9404 - Validation IoU: 0.9220\n",
            "Epoch [83/100] - Train IoU: 0.9281 - Validation IoU: 0.9190\n",
            "Epoch [84/100] - Train IoU: 0.9295 - Validation IoU: 0.9159\n",
            "Epoch [85/100] - Train IoU: 0.9411 - Validation IoU: 0.9221\n",
            "Epoch [86/100] - Train IoU: 0.9420 - Validation IoU: 0.9299\n",
            "Epoch [87/100] - Train IoU: 0.9449 - Validation IoU: 0.9293\n",
            "Epoch [88/100] - Train IoU: 0.9350 - Validation IoU: 0.9258\n",
            "Epoch [89/100] - Train IoU: 0.9467 - Validation IoU: 0.9214\n",
            "Epoch [90/100] - Train IoU: 0.9501 - Validation IoU: 0.9130\n",
            "Epoch [91/100] - Train IoU: 0.9379 - Validation IoU: 0.9041\n",
            "Epoch [92/100] - Train IoU: 0.9448 - Validation IoU: 0.9143\n",
            "Epoch [93/100] - Train IoU: 0.9478 - Validation IoU: 0.9232\n",
            "Epoch [94/100] - Train IoU: 0.9519 - Validation IoU: 0.9286\n",
            "Epoch [95/100] - Train IoU: 0.9432 - Validation IoU: 0.9330\n",
            "Epoch [96/100] - Train IoU: 0.9377 - Validation IoU: 0.9284\n",
            "Epoch [97/100] - Train IoU: 0.9524 - Validation IoU: 0.9126\n",
            "Epoch [98/100] - Train IoU: 0.9450 - Validation IoU: 0.9126\n",
            "Epoch [99/100] - Train IoU: 0.9492 - Validation IoU: 0.9207\n",
            "Epoch [100/100] - Train IoU: 0.9528 - Validation IoU: 0.9260\n",
            "Model saved successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import nibabel as nib\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import random\n",
        "import segmentation_models_pytorch as smp\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "num_classes = 7\n",
        "batch_size = 4\n",
        "img_root = \"/home/ealam/JHIR_Hip_Knee_Datasets/Hip/Images\"\n",
        "mask_root = \"/home/ealam/JHIR_Hip_Knee_Datasets/Hip/Annotations\"\n",
        "metadata_path = \"/home/ealam/JHIR_Hip_Knee_Datasets/Hip/segmentation_with_racegender.csv\"\n",
        "\n",
        "\n",
        "test_augmentations = A.Compose([\n",
        "    A.Resize(height=512, width=512),\n",
        "    A.Normalize(mean=(0.485, 0.485, 0.485), std=(0.229, 0.229, 0.229)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "class MulticlassHipSegmentationDataset(Dataset):\n",
        "    def __init__(self, img_root, mask_root, metadata_df, paired_files, num_classes, transforms=None, preprocessing=None):\n",
        "        self.img_root = img_root\n",
        "        self.mask_root = mask_root\n",
        "        self.metadata_df = metadata_df\n",
        "        self.paired_files = paired_files\n",
        "        self.num_classes = num_classes\n",
        "        self.transforms = transforms\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paired_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_file, mask_file = self.paired_files[idx]\n",
        "        if not os.path.exists(os.path.join(self.mask_root, mask_file)):\n",
        "            return None\n",
        "\n",
        "        dicom_image = pydicom.dcmread(os.path.join(self.img_root, image_file))\n",
        "        image = dicom_image.pixel_array.astype(np.float32)\n",
        "        image = cv2.resize(image, (512, 512))\n",
        "\n",
        "\n",
        "        image = np.stack([image] * 3, axis=-1)\n",
        "\n",
        "        annotation = nib.load(os.path.join(self.mask_root, mask_file))\n",
        "        annotation_data = annotation.get_fdata()\n",
        "        if len(annotation_data.shape) == 3:\n",
        "            annotation_data = annotation_data[:, :, 0]\n",
        "\n",
        "        annotation_data = self.calculate_flipped_rotated_mask(annotation_data)\n",
        "        annotation_data = cv2.resize(annotation_data, (512, 512))\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            transformed = self.transforms(image=image, mask=annotation_data)\n",
        "            image = transformed[\"image\"]\n",
        "            annotation_data = transformed[\"mask\"]\n",
        "\n",
        "        annotation_data_onehot = self.one_hot_encode(annotation_data)\n",
        "\n",
        "        if self.preprocessing is not None:\n",
        "            transformed = self.preprocessing(image=image, mask=annotation_data_onehot)\n",
        "            image = transformed[\"image\"]\n",
        "            annotation_data_onehot = transformed[\"mask\"]\n",
        "\n",
        "        patient_id = int(float(image_file.split(\".\")[0]))\n",
        "        racegender_info = self.metadata_df.loc[self.metadata_df['id'] == patient_id]['racegender'].values\n",
        "        racegender = racegender_info[0] if racegender_info.size > 0 else 'Unknown'\n",
        "\n",
        "        return image, annotation_data_onehot, racegender\n",
        "\n",
        "    def one_hot_encode(self, mask):\n",
        "        one_hot_mask = np.zeros((self.num_classes, *mask.shape), dtype=np.float32)\n",
        "        for class_idx in range(self.num_classes):\n",
        "            one_hot_mask[class_idx][mask == class_idx] = 1.0\n",
        "        return one_hot_mask\n",
        "\n",
        "    def calculate_flipped_rotated_mask(self, mask):\n",
        "        rotated_mask = cv2.rotate(mask, cv2.ROTATE_90_CLOCKWISE)\n",
        "        flipped_rotated_mask = cv2.flip(rotated_mask, 1)\n",
        "        return flipped_rotated_mask\n",
        "\n",
        "metadata_df = pd.read_csv(metadata_path)\n",
        "\n",
        "image_files = sorted(os.listdir(img_root))\n",
        "mask_files = sorted(os.listdir(mask_root))\n",
        "\n",
        "paired_files = []\n",
        "\n",
        "for image_file in image_files:\n",
        "    image_id = os.path.splitext(image_file)[0]\n",
        "    mask_file = f\"{image_id}.nii.gz\"\n",
        "    if mask_file in mask_files:\n",
        "        paired_files.append((image_file, mask_file))\n",
        "\n",
        "random.shuffle(paired_files)\n",
        "\n",
        "train_size = int(0.7 * len(paired_files))\n",
        "valid_size = int(0.1 * len(paired_files))\n",
        "test_size = len(paired_files) - train_size - valid_size\n",
        "\n",
        "train_pairs = paired_files[:train_size]\n",
        "valid_pairs = paired_files[train_size:train_size + valid_size]\n",
        "test_pairs = paired_files[train_size + valid_size:]\n",
        "\n",
        "train_set = MulticlassHipSegmentationDataset(\n",
        "    img_root, mask_root, metadata_df, train_pairs, num_classes,\n",
        "    transforms=test_augmentations\n",
        ")\n",
        "\n",
        "def train_fpn_model(num_epochs=100, encoder_name=\"resnet18\"):\n",
        "\n",
        "    model = smp.FPN(\n",
        "        encoder_name=encoder_name,\n",
        "        encoder_weights=\"imagenet\",\n",
        "        in_channels=3,\n",
        "        classes=num_classes,\n",
        "    )\n",
        "\n",
        "    device = torch.device(\"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    valid_set = MulticlassHipSegmentationDataset(\n",
        "        img_root, mask_root, metadata_df, valid_pairs, num_classes,\n",
        "        transforms=test_augmentations\n",
        "    )\n",
        "\n",
        "    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "        model.train()\n",
        "        train_iou_list = []\n",
        "\n",
        "        for batch_idx, (images, masks, racegender) in enumerate(train_loader):\n",
        "            if images is None:\n",
        "                continue\n",
        "\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "\n",
        "            predicted_masks = torch.argmax(outputs, dim=1)\n",
        "            loss = criterion(outputs, masks.argmax(dim=1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_iou = jaccard_score(\n",
        "                masks.argmax(dim=1).cpu().numpy().flatten(),\n",
        "                predicted_masks.cpu().numpy().flatten(),\n",
        "                average='micro'\n",
        "            )\n",
        "            train_iou_list.append(train_iou)\n",
        "\n",
        "        model.eval()\n",
        "        valid_iou_list = []\n",
        "\n",
        "        for batch_idx, (images, masks, racegender) in enumerate(valid_loader):\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(images)\n",
        "            predicted_masks = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            valid_iou = jaccard_score(\n",
        "                masks.argmax(dim=1).cpu().numpy().flatten(),\n",
        "                predicted_masks.cpu().numpy().flatten(),\n",
        "                average='micro'\n",
        "            )\n",
        "\n",
        "            valid_iou_list.append(valid_iou)\n",
        "\n",
        "        train_iou_avg = np.mean(train_iou_list)\n",
        "        valid_iou_avg = np.mean(valid_iou_list)\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}] - Train IoU: {train_iou_avg:.4f} - Validation IoU: {valid_iou_avg:.4f}\")\n",
        "\n",
        "\n",
        "    torch.save(model.state_dict(), 'fpn_model_Hip_init.pth')\n",
        "\n",
        "\n",
        "    test_set = MulticlassHipSegmentationDataset(\n",
        "        img_root, mask_root, metadata_df, test_pairs, num_classes,\n",
        "        transforms=test_augmentations\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    model.eval()\n",
        "    test_iou_list = []\n",
        "\n",
        "    for batch_idx, (images, masks, racegender) in enumerate(test_loader):\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(images)\n",
        "        predicted_masks = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        test_iou = jaccard_score(\n",
        "            masks.argmax(dim=1).cpu().numpy().flatten(),\n",
        "            predicted_masks.cpu().numpy().flatten(),\n",
        "            average='micro'\n",
        "        )\n",
        "\n",
        "        test_iou_list.append(test_iou)\n",
        "\n",
        "    test_iou_avg = np.mean(test_iou_list)\n",
        "\n",
        "    print(\"Model saved successfully.\")\n",
        "\n",
        "\n",
        "print(\"Training FPN ..\")\n",
        "train_fpn_model(encoder_name=\"resnet18\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b0ab7b8",
      "metadata": {
        "id": "7b0ab7b8",
        "outputId": "d1e43630-0003-46eb-dac8-bb041439f31c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training PAN ..\n",
            "Epoch 1/100 - Training IoU: 0.4583 - Validation IoU: 0.5184\n",
            "Epoch 2/100 - Training IoU: 0.4774 - Validation IoU: 0.5087\n",
            "Epoch 3/100 - Training IoU: 0.5381 - Validation IoU: 0.4961\n",
            "Epoch 4/100 - Training IoU: 0.5393 - Validation IoU: 0.4822\n",
            "Epoch 5/100 - Training IoU: 0.5395 - Validation IoU: 0.5013\n",
            "Epoch 6/100 - Training IoU: 0.5902 - Validation IoU: 0.5329\n",
            "Epoch 7/100 - Training IoU: 0.6030 - Validation IoU: 0.5667\n",
            "Epoch 8/100 - Training IoU: 0.6316 - Validation IoU: 0.5805\n",
            "Epoch 9/100 - Training IoU: 0.6552 - Validation IoU: 0.5810\n",
            "Epoch 10/100 - Training IoU: 0.6809 - Validation IoU: 0.5912\n",
            "Epoch 11/100 - Training IoU: 0.7089 - Validation IoU: 0.6190\n",
            "Epoch 12/100 - Training IoU: 0.7000 - Validation IoU: 0.6575\n",
            "Epoch 13/100 - Training IoU: 0.7420 - Validation IoU: 0.6974\n",
            "Epoch 14/100 - Training IoU: 0.7261 - Validation IoU: 0.7258\n",
            "Epoch 15/100 - Training IoU: 0.7649 - Validation IoU: 0.7325\n",
            "Epoch 16/100 - Training IoU: 0.7907 - Validation IoU: 0.7268\n",
            "Epoch 17/100 - Training IoU: 0.7886 - Validation IoU: 0.7417\n",
            "Epoch 18/100 - Training IoU: 0.7941 - Validation IoU: 0.7615\n",
            "Epoch 19/100 - Training IoU: 0.8135 - Validation IoU: 0.7756\n",
            "Epoch 20/100 - Training IoU: 0.8243 - Validation IoU: 0.8028\n",
            "Epoch 21/100 - Training IoU: 0.8353 - Validation IoU: 0.8127\n",
            "Epoch 22/100 - Training IoU: 0.8441 - Validation IoU: 0.8319\n",
            "Epoch 23/100 - Training IoU: 0.8462 - Validation IoU: 0.8395\n",
            "Epoch 24/100 - Training IoU: 0.8382 - Validation IoU: 0.8444\n",
            "Epoch 25/100 - Training IoU: 0.8554 - Validation IoU: 0.8409\n",
            "Epoch 26/100 - Training IoU: 0.8684 - Validation IoU: 0.8383\n",
            "Epoch 27/100 - Training IoU: 0.8816 - Validation IoU: 0.8393\n",
            "Epoch 28/100 - Training IoU: 0.8795 - Validation IoU: 0.8452\n",
            "Epoch 29/100 - Training IoU: 0.8807 - Validation IoU: 0.8532\n",
            "Epoch 30/100 - Training IoU: 0.8689 - Validation IoU: 0.8631\n",
            "Epoch 31/100 - Training IoU: 0.8758 - Validation IoU: 0.8743\n",
            "Epoch 32/100 - Training IoU: 0.8905 - Validation IoU: 0.8760\n",
            "Epoch 33/100 - Training IoU: 0.8897 - Validation IoU: 0.8770\n",
            "Epoch 34/100 - Training IoU: 0.8875 - Validation IoU: 0.8776\n",
            "Epoch 35/100 - Training IoU: 0.8990 - Validation IoU: 0.8731\n",
            "Epoch 36/100 - Training IoU: 0.9036 - Validation IoU: 0.8681\n",
            "Epoch 37/100 - Training IoU: 0.9030 - Validation IoU: 0.8677\n",
            "Epoch 38/100 - Training IoU: 0.9097 - Validation IoU: 0.8691\n",
            "Epoch 39/100 - Training IoU: 0.9197 - Validation IoU: 0.8702\n",
            "Epoch 40/100 - Training IoU: 0.9098 - Validation IoU: 0.8709\n",
            "Epoch 41/100 - Training IoU: 0.9146 - Validation IoU: 0.8663\n",
            "Epoch 42/100 - Training IoU: 0.9177 - Validation IoU: 0.8637\n",
            "Epoch 43/100 - Training IoU: 0.9171 - Validation IoU: 0.8623\n",
            "Epoch 44/100 - Training IoU: 0.9239 - Validation IoU: 0.8620\n",
            "Epoch 45/100 - Training IoU: 0.9290 - Validation IoU: 0.8642\n",
            "Epoch 46/100 - Training IoU: 0.9248 - Validation IoU: 0.8689\n",
            "Epoch 47/100 - Training IoU: 0.9199 - Validation IoU: 0.8719\n",
            "Epoch 48/100 - Training IoU: 0.9243 - Validation IoU: 0.8744\n",
            "Epoch 49/100 - Training IoU: 0.9263 - Validation IoU: 0.8742\n",
            "Epoch 50/100 - Training IoU: 0.9307 - Validation IoU: 0.8743\n",
            "Epoch 51/100 - Training IoU: 0.9336 - Validation IoU: 0.8742\n",
            "Epoch 52/100 - Training IoU: 0.9331 - Validation IoU: 0.8724\n",
            "Epoch 53/100 - Training IoU: 0.9351 - Validation IoU: 0.8712\n",
            "Epoch 54/100 - Training IoU: 0.9407 - Validation IoU: 0.8706\n",
            "Epoch 55/100 - Training IoU: 0.9365 - Validation IoU: 0.8690\n",
            "Epoch 56/100 - Training IoU: 0.9418 - Validation IoU: 0.8692\n",
            "Epoch 57/100 - Training IoU: 0.9394 - Validation IoU: 0.8668\n",
            "Epoch 58/100 - Training IoU: 0.9374 - Validation IoU: 0.8688\n",
            "Epoch 59/100 - Training IoU: 0.9431 - Validation IoU: 0.8705\n",
            "Epoch 60/100 - Training IoU: 0.9456 - Validation IoU: 0.8723\n",
            "Epoch 61/100 - Training IoU: 0.9427 - Validation IoU: 0.8745\n",
            "Epoch 62/100 - Training IoU: 0.9435 - Validation IoU: 0.8761\n",
            "Epoch 63/100 - Training IoU: 0.9459 - Validation IoU: 0.8811\n",
            "Epoch 64/100 - Training IoU: 0.9447 - Validation IoU: 0.8824\n",
            "Epoch 65/100 - Training IoU: 0.9480 - Validation IoU: 0.8818\n",
            "Epoch 66/100 - Training IoU: 0.9469 - Validation IoU: 0.8816\n",
            "Epoch 67/100 - Training IoU: 0.9511 - Validation IoU: 0.8827\n",
            "Epoch 68/100 - Training IoU: 0.9510 - Validation IoU: 0.8833\n",
            "Epoch 69/100 - Training IoU: 0.9517 - Validation IoU: 0.8829\n",
            "Epoch 70/100 - Training IoU: 0.9498 - Validation IoU: 0.8849\n",
            "Epoch 71/100 - Training IoU: 0.9554 - Validation IoU: 0.8857\n",
            "Epoch 72/100 - Training IoU: 0.9445 - Validation IoU: 0.8877\n",
            "Epoch 73/100 - Training IoU: 0.9560 - Validation IoU: 0.8875\n",
            "Epoch 74/100 - Training IoU: 0.9524 - Validation IoU: 0.8866\n",
            "Epoch 75/100 - Training IoU: 0.9549 - Validation IoU: 0.8848\n",
            "Epoch 76/100 - Training IoU: 0.9548 - Validation IoU: 0.8821\n",
            "Epoch 77/100 - Training IoU: 0.9581 - Validation IoU: 0.8805\n",
            "Epoch 78/100 - Training IoU: 0.9570 - Validation IoU: 0.8806\n",
            "Epoch 79/100 - Training IoU: 0.9598 - Validation IoU: 0.8810\n",
            "Epoch 80/100 - Training IoU: 0.9608 - Validation IoU: 0.8819\n",
            "Epoch 81/100 - Training IoU: 0.9604 - Validation IoU: 0.8832\n",
            "Epoch 82/100 - Training IoU: 0.9589 - Validation IoU: 0.8845\n",
            "Epoch 83/100 - Training IoU: 0.9587 - Validation IoU: 0.8841\n",
            "Epoch 84/100 - Training IoU: 0.9556 - Validation IoU: 0.8869\n",
            "Epoch 85/100 - Training IoU: 0.9594 - Validation IoU: 0.8886\n",
            "Epoch 86/100 - Training IoU: 0.9610 - Validation IoU: 0.8912\n",
            "Epoch 87/100 - Training IoU: 0.9622 - Validation IoU: 0.8931\n",
            "Epoch 88/100 - Training IoU: 0.9602 - Validation IoU: 0.8934\n",
            "Epoch 89/100 - Training IoU: 0.9573 - Validation IoU: 0.8917\n",
            "Epoch 90/100 - Training IoU: 0.9586 - Validation IoU: 0.8897\n",
            "Epoch 91/100 - Training IoU: 0.9604 - Validation IoU: 0.8884\n",
            "Epoch 92/100 - Training IoU: 0.9616 - Validation IoU: 0.8873\n",
            "Epoch 93/100 - Training IoU: 0.9638 - Validation IoU: 0.8913\n",
            "Epoch 94/100 - Training IoU: 0.9644 - Validation IoU: 0.8932\n",
            "Epoch 95/100 - Training IoU: 0.9604 - Validation IoU: 0.8937\n",
            "Epoch 96/100 - Training IoU: 0.9625 - Validation IoU: 0.8951\n",
            "Epoch 97/100 - Training IoU: 0.9628 - Validation IoU: 0.8959\n",
            "Epoch 98/100 - Training IoU: 0.9637 - Validation IoU: 0.8978\n",
            "Epoch 99/100 - Training IoU: 0.9644 - Validation IoU: 0.8958\n",
            "Epoch 100/100 - Training IoU: 0.9619 - Validation IoU: 0.8942\n",
            "Model saved \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import nibabel as nib\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import random\n",
        "import segmentation_models_pytorch as smp\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "num_classes = 7\n",
        "batch_size = 4\n",
        "img_root = \"/home/ealam/JHIR_Hip_Knee_Datasets/Hip/Images\"\n",
        "mask_root = \"/home/ealam/JHIR_Hip_Knee_Datasets/Hip/Annotations\"\n",
        "metadata_path = \"/home/ealam/JHIR_Hip_Knee_Datasets/Hip/segmentation_with_racegender.csv\"\n",
        "\n",
        "\n",
        "test_augmentations = A.Compose([\n",
        "    A.Resize(height=512, width=512),\n",
        "    A.Normalize(mean=(0.485, 0.485, 0.485), std=(0.229, 0.229, 0.229)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "class MulticlassHipSegmentationDataset(Dataset):\n",
        "    def __init__(self, img_root, mask_root, metadata_df, paired_files, num_classes, transforms=None, preprocessing=None):\n",
        "        self.img_root = img_root\n",
        "        self.mask_root = mask_root\n",
        "        self.metadata_df = metadata_df\n",
        "        self.paired_files = paired_files\n",
        "        self.num_classes = num_classes\n",
        "        self.transforms = transforms\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paired_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_file, mask_file = self.paired_files[idx]\n",
        "        if not os.path.exists(os.path.join(self.mask_root, mask_file)):\n",
        "            return None\n",
        "\n",
        "        dicom_image = pydicom.dcmread(os.path.join(self.img_root, image_file))\n",
        "        image = dicom_image.pixel_array.astype(np.float32)\n",
        "        image = cv2.resize(image, (512, 512))\n",
        "\n",
        "\n",
        "        image = np.stack([image] * 3, axis=-1)\n",
        "\n",
        "        annotation = nib.load(os.path.join(self.mask_root, mask_file))\n",
        "        annotation_data = annotation.get_fdata()\n",
        "        if len(annotation_data.shape) == 3:\n",
        "            annotation_data = annotation_data[:, :, 0]\n",
        "\n",
        "        annotation_data = self.calculate_flipped_rotated_mask(annotation_data)\n",
        "        annotation_data = cv2.resize(annotation_data, (512, 512))\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            transformed = self.transforms(image=image, mask=annotation_data)\n",
        "            image = transformed[\"image\"]\n",
        "            annotation_data = transformed[\"mask\"]\n",
        "\n",
        "        annotation_data_onehot = self.one_hot_encode(annotation_data)\n",
        "\n",
        "        if self.preprocessing is not None:\n",
        "            transformed = self.preprocessing(image=image, mask=annotation_data_onehot)\n",
        "            image = transformed[\"image\"]\n",
        "            annotation_data_onehot = transformed[\"mask\"]\n",
        "\n",
        "        patient_id = int(float(image_file.split(\".\")[0]))\n",
        "        racegender_info = self.metadata_df.loc[self.metadata_df['id'] == patient_id]['racegender'].values\n",
        "        racegender = racegender_info[0] if racegender_info.size > 0 else 'Unknown'\n",
        "\n",
        "        return image, annotation_data_onehot, racegender\n",
        "\n",
        "    def one_hot_encode(self, mask):\n",
        "        one_hot_mask = np.zeros((self.num_classes, *mask.shape), dtype=np.float32)\n",
        "        for class_idx in range(self.num_classes):\n",
        "            one_hot_mask[class_idx][mask == class_idx] = 1.0\n",
        "        return one_hot_mask\n",
        "\n",
        "    def calculate_flipped_rotated_mask(self, mask):\n",
        "        rotated_mask = cv2.rotate(mask, cv2.ROTATE_90_CLOCKWISE)\n",
        "        flipped_rotated_mask = cv2.flip(rotated_mask, 1)\n",
        "        return flipped_rotated_mask\n",
        "\n",
        "metadata_df = pd.read_csv(metadata_path)\n",
        "\n",
        "image_files = sorted(os.listdir(img_root))\n",
        "mask_files = sorted(os.listdir(mask_root))\n",
        "\n",
        "paired_files = []\n",
        "\n",
        "for image_file in image_files:\n",
        "    image_id = os.path.splitext(image_file)[0]\n",
        "    mask_file = f\"{image_id}.nii.gz\"\n",
        "    if mask_file in mask_files:\n",
        "        paired_files.append((image_file, mask_file))\n",
        "\n",
        "random.shuffle(paired_files)\n",
        "\n",
        "train_size = int(0.7 * len(paired_files))\n",
        "valid_size = int(0.1 * len(paired_files))\n",
        "test_size = len(paired_files) - train_size - valid_size\n",
        "\n",
        "train_pairs = paired_files[:train_size]\n",
        "valid_pairs = paired_files[train_size:train_size + valid_size]\n",
        "test_pairs = paired_files[train_size + valid_size:]\n",
        "\n",
        "train_set = MulticlassHipSegmentationDataset(\n",
        "    img_root, mask_root, metadata_df, train_pairs, num_classes,\n",
        "    transforms=test_augmentations\n",
        ")\n",
        "\n",
        "def train_pan_model(num_epochs=100, encoder_name=\"resnet18\"):\n",
        "\n",
        "    model = smp.PAN(\n",
        "        encoder_name=encoder_name,\n",
        "        encoder_weights=\"imagenet\",\n",
        "        in_channels=3,\n",
        "        classes=num_classes,\n",
        "    )\n",
        "\n",
        "    device = torch.device(\"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    valid_set = MulticlassHipSegmentationDataset(\n",
        "        img_root, mask_root, metadata_df, valid_pairs, num_classes,\n",
        "        transforms=test_augmentations\n",
        "    )\n",
        "\n",
        "    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "        if len(train_loader) == 0:\n",
        "            continue\n",
        "\n",
        "        model.train()\n",
        "        train_iou_list = []\n",
        "\n",
        "        for batch_idx, (images, masks, racegender) in enumerate(train_loader):\n",
        "            if images is None or masks is None:\n",
        "                continue\n",
        "\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "            if images.size(0) < 2:\n",
        "                continue\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(images)\n",
        "\n",
        "            predicted_masks = torch.argmax(outputs, dim=1)\n",
        "            loss = criterion(outputs, masks.argmax(dim=1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_iou = jaccard_score(\n",
        "                masks.argmax(dim=1).cpu().numpy().flatten(),\n",
        "                predicted_masks.cpu().numpy().flatten(),\n",
        "                average='micro'\n",
        "            )\n",
        "            train_iou_list.append(train_iou)\n",
        "\n",
        "        model.eval()\n",
        "        valid_iou_list = []\n",
        "\n",
        "        for batch_idx, (images, masks, racegender) in enumerate(valid_loader):\n",
        "            if images is None or masks is None:\n",
        "                continue\n",
        "\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(images)\n",
        "\n",
        "            predicted_masks = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            valid_iou = jaccard_score(\n",
        "                masks.argmax(dim=1).cpu().numpy().flatten(),\n",
        "                predicted_masks.cpu().numpy().flatten(),\n",
        "                average='micro'\n",
        "            )\n",
        "\n",
        "            valid_iou_list.append(valid_iou)\n",
        "\n",
        "        train_iou_avg = np.mean(train_iou_list)\n",
        "        valid_iou_avg = np.mean(valid_iou_list)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs} - Training IoU: {train_iou_avg:.4f} - Validation IoU: {valid_iou_avg:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "    torch.save(model.state_dict(), \"panhip_init.pth\")\n",
        "    print(\"Model saved \")\n",
        "\n",
        "\n",
        "print(\"Training PAN ..\")\n",
        "train_pan_model(encoder_name=\"resnet18\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "586d9cd5",
      "metadata": {
        "id": "586d9cd5",
        "outputId": "82a7afeb-d383-4555-91fc-f5ba55aae9a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training MAnet ..\n",
            "Epoch [1/100] - Train IoU: 0.0318 - Validation IoU: 0.0223\n",
            "Epoch [2/100] - Train IoU: 0.0363 - Validation IoU: 0.0171\n",
            "Epoch [3/100] - Train IoU: 0.0449 - Validation IoU: 0.0254\n",
            "Epoch [4/100] - Train IoU: 0.0596 - Validation IoU: 0.0483\n",
            "Epoch [5/100] - Train IoU: 0.0673 - Validation IoU: 0.0764\n",
            "Epoch [6/100] - Train IoU: 0.0868 - Validation IoU: 0.1112\n",
            "Epoch [7/100] - Train IoU: 0.1122 - Validation IoU: 0.1391\n",
            "Epoch [8/100] - Train IoU: 0.1275 - Validation IoU: 0.1486\n",
            "Epoch [9/100] - Train IoU: 0.1666 - Validation IoU: 0.1591\n",
            "Epoch [10/100] - Train IoU: 0.1745 - Validation IoU: 0.1778\n",
            "Epoch [11/100] - Train IoU: 0.2042 - Validation IoU: 0.1796\n",
            "Epoch [12/100] - Train IoU: 0.2199 - Validation IoU: 0.1935\n",
            "Epoch [13/100] - Train IoU: 0.2437 - Validation IoU: 0.2069\n",
            "Epoch [14/100] - Train IoU: 0.2677 - Validation IoU: 0.2177\n",
            "Epoch [15/100] - Train IoU: 0.2939 - Validation IoU: 0.2314\n",
            "Epoch [16/100] - Train IoU: 0.2975 - Validation IoU: 0.2468\n",
            "Epoch [17/100] - Train IoU: 0.3337 - Validation IoU: 0.2589\n",
            "Epoch [18/100] - Train IoU: 0.3483 - Validation IoU: 0.2661\n",
            "Epoch [19/100] - Train IoU: 0.3508 - Validation IoU: 0.2786\n",
            "Epoch [20/100] - Train IoU: 0.3685 - Validation IoU: 0.2896\n",
            "Epoch [21/100] - Train IoU: 0.3997 - Validation IoU: 0.3096\n",
            "Epoch [22/100] - Train IoU: 0.4236 - Validation IoU: 0.3227\n",
            "Epoch [23/100] - Train IoU: 0.4765 - Validation IoU: 0.3439\n",
            "Epoch [24/100] - Train IoU: 0.5150 - Validation IoU: 0.3982\n",
            "Epoch [25/100] - Train IoU: 0.5675 - Validation IoU: 0.4561\n",
            "Epoch [26/100] - Train IoU: 0.6244 - Validation IoU: 0.5290\n",
            "Epoch [27/100] - Train IoU: 0.6165 - Validation IoU: 0.5880\n",
            "Epoch [28/100] - Train IoU: 0.6817 - Validation IoU: 0.6319\n",
            "Epoch [29/100] - Train IoU: 0.6796 - Validation IoU: 0.6588\n",
            "Epoch [30/100] - Train IoU: 0.7418 - Validation IoU: 0.6725\n",
            "Epoch [31/100] - Train IoU: 0.7482 - Validation IoU: 0.6792\n",
            "Epoch [32/100] - Train IoU: 0.7496 - Validation IoU: 0.6968\n",
            "Epoch [33/100] - Train IoU: 0.7672 - Validation IoU: 0.6991\n",
            "Epoch [34/100] - Train IoU: 0.7683 - Validation IoU: 0.7041\n",
            "Epoch [35/100] - Train IoU: 0.7877 - Validation IoU: 0.7119\n",
            "Epoch [36/100] - Train IoU: 0.8098 - Validation IoU: 0.7308\n",
            "Epoch [37/100] - Train IoU: 0.7919 - Validation IoU: 0.7436\n",
            "Epoch [38/100] - Train IoU: 0.8102 - Validation IoU: 0.7496\n",
            "Epoch [39/100] - Train IoU: 0.8381 - Validation IoU: 0.7757\n",
            "Epoch [40/100] - Train IoU: 0.8534 - Validation IoU: 0.7904\n",
            "Epoch [41/100] - Train IoU: 0.8371 - Validation IoU: 0.8036\n",
            "Epoch [42/100] - Train IoU: 0.8484 - Validation IoU: 0.8068\n",
            "Epoch [43/100] - Train IoU: 0.8655 - Validation IoU: 0.8113\n",
            "Epoch [44/100] - Train IoU: 0.8662 - Validation IoU: 0.8384\n",
            "Epoch [45/100] - Train IoU: 0.8574 - Validation IoU: 0.8498\n",
            "Epoch [46/100] - Train IoU: 0.8790 - Validation IoU: 0.8526\n",
            "Epoch [47/100] - Train IoU: 0.8866 - Validation IoU: 0.8485\n",
            "Epoch [48/100] - Train IoU: 0.8951 - Validation IoU: 0.8585\n",
            "Epoch [49/100] - Train IoU: 0.9009 - Validation IoU: 0.8743\n",
            "Epoch [50/100] - Train IoU: 0.8971 - Validation IoU: 0.8823\n",
            "Epoch [51/100] - Train IoU: 0.8905 - Validation IoU: 0.8780\n",
            "Epoch [52/100] - Train IoU: 0.9121 - Validation IoU: 0.8862\n",
            "Epoch [53/100] - Train IoU: 0.9027 - Validation IoU: 0.8914\n",
            "Epoch [54/100] - Train IoU: 0.9132 - Validation IoU: 0.8953\n",
            "Epoch [55/100] - Train IoU: 0.9121 - Validation IoU: 0.8967\n",
            "Epoch [56/100] - Train IoU: 0.9152 - Validation IoU: 0.8976\n",
            "Epoch [57/100] - Train IoU: 0.9167 - Validation IoU: 0.8996\n",
            "Epoch [58/100] - Train IoU: 0.9264 - Validation IoU: 0.8954\n",
            "Epoch [59/100] - Train IoU: 0.9267 - Validation IoU: 0.9054\n",
            "Epoch [60/100] - Train IoU: 0.9315 - Validation IoU: 0.9109\n",
            "Epoch [61/100] - Train IoU: 0.9324 - Validation IoU: 0.9082\n",
            "Epoch [62/100] - Train IoU: 0.9316 - Validation IoU: 0.9041\n",
            "Epoch [63/100] - Train IoU: 0.9335 - Validation IoU: 0.9033\n",
            "Epoch [64/100] - Train IoU: 0.9392 - Validation IoU: 0.9170\n",
            "Epoch [65/100] - Train IoU: 0.9395 - Validation IoU: 0.9182\n",
            "Epoch [66/100] - Train IoU: 0.9419 - Validation IoU: 0.9140\n",
            "Epoch [67/100] - Train IoU: 0.9462 - Validation IoU: 0.9193\n",
            "Epoch [68/100] - Train IoU: 0.9444 - Validation IoU: 0.9221\n",
            "Epoch [69/100] - Train IoU: 0.9298 - Validation IoU: 0.9175\n",
            "Epoch [70/100] - Train IoU: 0.9457 - Validation IoU: 0.9228\n",
            "Epoch [71/100] - Train IoU: 0.9461 - Validation IoU: 0.9218\n",
            "Epoch [72/100] - Train IoU: 0.9460 - Validation IoU: 0.9216\n",
            "Epoch [73/100] - Train IoU: 0.9434 - Validation IoU: 0.9248\n",
            "Epoch [74/100] - Train IoU: 0.9480 - Validation IoU: 0.9221\n",
            "Epoch [75/100] - Train IoU: 0.9329 - Validation IoU: 0.9186\n",
            "Epoch [76/100] - Train IoU: 0.9474 - Validation IoU: 0.9193\n",
            "Epoch [77/100] - Train IoU: 0.9377 - Validation IoU: 0.9252\n",
            "Epoch [78/100] - Train IoU: 0.9492 - Validation IoU: 0.9223\n",
            "Epoch [79/100] - Train IoU: 0.9308 - Validation IoU: 0.9314\n",
            "Epoch [80/100] - Train IoU: 0.9503 - Validation IoU: 0.9349\n",
            "Epoch [81/100] - Train IoU: 0.9519 - Validation IoU: 0.9379\n",
            "Epoch [82/100] - Train IoU: 0.9457 - Validation IoU: 0.9318\n",
            "Epoch [83/100] - Train IoU: 0.9493 - Validation IoU: 0.9278\n",
            "Epoch [84/100] - Train IoU: 0.9539 - Validation IoU: 0.9311\n",
            "Epoch [85/100] - Train IoU: 0.9517 - Validation IoU: 0.9355\n",
            "Epoch [86/100] - Train IoU: 0.9577 - Validation IoU: 0.9415\n",
            "Epoch [87/100] - Train IoU: 0.9589 - Validation IoU: 0.9432\n",
            "Epoch [88/100] - Train IoU: 0.9476 - Validation IoU: 0.9403\n",
            "Epoch [89/100] - Train IoU: 0.9495 - Validation IoU: 0.9394\n",
            "Epoch [90/100] - Train IoU: 0.9479 - Validation IoU: 0.9426\n",
            "Epoch [91/100] - Train IoU: 0.9607 - Validation IoU: 0.9458\n",
            "Epoch [92/100] - Train IoU: 0.9557 - Validation IoU: 0.9432\n",
            "Epoch [93/100] - Train IoU: 0.9513 - Validation IoU: 0.9415\n",
            "Epoch [94/100] - Train IoU: 0.9553 - Validation IoU: 0.9444\n",
            "Epoch [95/100] - Train IoU: 0.9563 - Validation IoU: 0.9461\n",
            "Epoch [96/100] - Train IoU: 0.9544 - Validation IoU: 0.9413\n",
            "Epoch [97/100] - Train IoU: 0.9500 - Validation IoU: 0.9404\n",
            "Epoch [98/100] - Train IoU: 0.9594 - Validation IoU: 0.9421\n",
            "Epoch [99/100] - Train IoU: 0.9558 - Validation IoU: 0.9441\n",
            "Epoch [100/100] - Train IoU: 0.9540 - Validation IoU: 0.9414\n",
            "Model saved successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import nibabel as nib\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import random\n",
        "import segmentation_models_pytorch as smp\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "num_classes = 7\n",
        "batch_size = 4\n",
        "img_root = \"/home/ealam/JHIR_Hip_Knee_Datasets/Hip/Images\"\n",
        "mask_root = \"/home/ealam/JHIR_Hip_Knee_Datasets/Hip/Annotations\"\n",
        "metadata_path = \"/home/ealam/JHIR_Hip_Knee_Datasets/Hip/segmentation_with_racegender.csv\"\n",
        "\n",
        "\n",
        "test_augmentations = A.Compose([\n",
        "    A.Resize(height=512, width=512),\n",
        "    A.Normalize(mean=(0.485, 0.485, 0.485), std=(0.229, 0.229, 0.229)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "class MulticlassHipSegmentationDataset(Dataset):\n",
        "    def __init__(self, img_root, mask_root, metadata_df, paired_files, num_classes, transforms=None, preprocessing=None):\n",
        "        self.img_root = img_root\n",
        "        self.mask_root = mask_root\n",
        "        self.metadata_df = metadata_df\n",
        "        self.paired_files = paired_files\n",
        "        self.num_classes = num_classes\n",
        "        self.transforms = transforms\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paired_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_file, mask_file = self.paired_files[idx]\n",
        "        if not os.path.exists(os.path.join(self.mask_root, mask_file)):\n",
        "            return None\n",
        "\n",
        "        dicom_image = pydicom.dcmread(os.path.join(self.img_root, image_file))\n",
        "        image = dicom_image.pixel_array.astype(np.float32)\n",
        "        image = cv2.resize(image, (512, 512))\n",
        "\n",
        "\n",
        "        image = np.stack([image] * 3, axis=-1)\n",
        "\n",
        "        annotation = nib.load(os.path.join(self.mask_root, mask_file))\n",
        "        annotation_data = annotation.get_fdata()\n",
        "        if len(annotation_data.shape) == 3:\n",
        "            annotation_data = annotation_data[:, :, 0]\n",
        "\n",
        "        annotation_data = self.calculate_flipped_rotated_mask(annotation_data)\n",
        "        annotation_data = cv2.resize(annotation_data, (512, 512))\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            transformed = self.transforms(image=image, mask=annotation_data)\n",
        "            image = transformed[\"image\"]\n",
        "            annotation_data = transformed[\"mask\"]\n",
        "\n",
        "        annotation_data_onehot = self.one_hot_encode(annotation_data)\n",
        "\n",
        "        if self.preprocessing is not None:\n",
        "            transformed = self.preprocessing(image=image, mask=annotation_data_onehot)\n",
        "            image = transformed[\"image\"]\n",
        "            annotation_data_onehot = transformed[\"mask\"]\n",
        "\n",
        "        patient_id = int(float(image_file.split(\".\")[0]))\n",
        "        racegender_info = self.metadata_df.loc[self.metadata_df['id'] == patient_id]['racegender'].values\n",
        "        racegender = racegender_info[0] if racegender_info.size > 0 else 'Unknown'\n",
        "\n",
        "        return image, annotation_data_onehot, racegender\n",
        "\n",
        "    def one_hot_encode(self, mask):\n",
        "        one_hot_mask = np.zeros((self.num_classes, *mask.shape), dtype=np.float32)\n",
        "        for class_idx in range(self.num_classes):\n",
        "            one_hot_mask[class_idx][mask == class_idx] = 1.0\n",
        "        return one_hot_mask\n",
        "\n",
        "    def calculate_flipped_rotated_mask(self, mask):\n",
        "        rotated_mask = cv2.rotate(mask, cv2.ROTATE_90_CLOCKWISE)\n",
        "        flipped_rotated_mask = cv2.flip(rotated_mask, 1)\n",
        "        return flipped_rotated_mask\n",
        "\n",
        "metadata_df = pd.read_csv(metadata_path)\n",
        "\n",
        "image_files = sorted(os.listdir(img_root))\n",
        "mask_files = sorted(os.listdir(mask_root))\n",
        "\n",
        "paired_files = []\n",
        "\n",
        "for image_file in image_files:\n",
        "    image_id = os.path.splitext(image_file)[0]\n",
        "    mask_file = f\"{image_id}.nii.gz\"\n",
        "    if mask_file in mask_files:\n",
        "        paired_files.append((image_file, mask_file))\n",
        "\n",
        "random.shuffle(paired_files)\n",
        "\n",
        "train_size = int(0.7 * len(paired_files))\n",
        "valid_size = int(0.1 * len(paired_files))\n",
        "test_size = len(paired_files) - train_size - valid_size\n",
        "\n",
        "train_pairs = paired_files[:train_size]\n",
        "valid_pairs = paired_files[train_size:train_size + valid_size]\n",
        "test_pairs = paired_files[train_size + valid_size:]\n",
        "\n",
        "train_set = MulticlassHipSegmentationDataset(\n",
        "    img_root, mask_root, metadata_df, train_pairs, num_classes,\n",
        "    transforms=test_augmentations\n",
        ")\n",
        "\n",
        "def train_manet_model(num_epochs=100, encoder_name=\"resnet18\"):\n",
        "\n",
        "    model = smp.MAnet(\n",
        "        encoder_name=encoder_name,\n",
        "        encoder_weights=\"imagenet\",\n",
        "        in_channels=3,\n",
        "        classes=num_classes,\n",
        "    )\n",
        "\n",
        "    device = torch.device(\"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    valid_set = MulticlassHipSegmentationDataset(\n",
        "        img_root, mask_root, metadata_df, valid_pairs, num_classes,\n",
        "        transforms=test_augmentations\n",
        "    )\n",
        "\n",
        "    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "        model.train()\n",
        "        train_iou_list = []\n",
        "\n",
        "        for batch_idx, (images, masks, racegender) in enumerate(train_loader):\n",
        "            if images is None:\n",
        "                continue\n",
        "\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "\n",
        "            predicted_masks = torch.argmax(outputs, dim=1)\n",
        "            loss = criterion(outputs, masks.argmax(dim=1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_iou = jaccard_score(\n",
        "                masks.argmax(dim=1).cpu().numpy().flatten(),\n",
        "                predicted_masks.cpu().numpy().flatten(),\n",
        "                average='micro'\n",
        "            )\n",
        "            train_iou_list.append(train_iou)\n",
        "\n",
        "        model.eval()\n",
        "        valid_iou_list = []\n",
        "\n",
        "        for batch_idx, (images, masks, racegender) in enumerate(valid_loader):\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(images)\n",
        "            predicted_masks = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            valid_iou = jaccard_score(\n",
        "                masks.argmax(dim=1).cpu().numpy().flatten(),\n",
        "                predicted_masks.cpu().numpy().flatten(),\n",
        "                average='micro'\n",
        "            )\n",
        "\n",
        "            valid_iou_list.append(valid_iou)\n",
        "\n",
        "        train_iou_avg = np.mean(train_iou_list)\n",
        "        valid_iou_avg = np.mean(valid_iou_list)\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}] - Train IoU: {train_iou_avg:.4f} - Validation IoU: {valid_iou_avg:.4f}\")\n",
        "\n",
        "\n",
        "    torch.save(model.state_dict(), 'manet_model_Hip_init.pth')\n",
        "\n",
        "\n",
        "    test_set = MulticlassHipSegmentationDataset(\n",
        "        img_root, mask_root, metadata_df, test_pairs, num_classes,\n",
        "        transforms=test_augmentations\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    model.eval()\n",
        "    test_iou_list = []\n",
        "\n",
        "    for batch_idx, (images, masks, racegender) in enumerate(test_loader):\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(images)\n",
        "        predicted_masks = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        test_iou = jaccard_score(\n",
        "            masks.argmax(dim=1).cpu().numpy().flatten(),\n",
        "            predicted_masks.cpu().numpy().flatten(),\n",
        "            average='micro'\n",
        "        )\n",
        "\n",
        "        test_iou_list.append(test_iou)\n",
        "\n",
        "    test_iou_avg = np.mean(test_iou_list)\n",
        "\n",
        "\n",
        "    print(\"Model saved successfully.\")\n",
        "\n",
        "\n",
        "print(\"Training MAnet ..\")\n",
        "train_manet_model(encoder_name=\"resnet18\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}